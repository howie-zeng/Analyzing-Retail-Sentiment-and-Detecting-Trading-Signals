{"cells":[{"cell_type":"code","execution_count":31,"metadata":{"executionInfo":{"elapsed":6970,"status":"ok","timestamp":1700962975288,"user":{"displayName":"Zixiao Wang","userId":"15997148754568851234"},"user_tz":300},"id":"4TVkFuf0fVWk"},"outputs":[],"source":["import numpy as np\n","\n","from transformers import Trainer\n","from transformers import TrainingArguments\n","from transformers import AutoModelForSequenceClassification\n","\n","from datasets import load_metric\n","from datasets import load_dataset\n","from datasets import load_from_disk\n","\n","from transformers import AutoTokenizer, DataCollatorWithPadding"]},{"cell_type":"code","execution_count":32,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1700962975289,"user":{"displayName":"Zixiao Wang","userId":"15997148754568851234"},"user_tz":300},"id":"UHtD8mn9fWil"},"outputs":[],"source":["# !pip install datasets"]},{"cell_type":"code","execution_count":33,"metadata":{"executionInfo":{"elapsed":4835,"status":"ok","timestamp":1700962980121,"user":{"displayName":"Zixiao Wang","userId":"15997148754568851234"},"user_tz":300},"id":"f4tLexhaYQJt"},"outputs":[{"name":"stderr","output_type":"stream","text":["Map: 100%|██████████| 808698/808698 [00:52<00:00, 15260.12 examples/s]\n","Map: 100%|██████████| 346585/346585 [00:24<00:00, 14162.34 examples/s]\n","Map: 100%|██████████| 5791/5791 [00:00<00:00, 16099.26 examples/s]\n"]}],"source":["raw_datasets = load_from_disk(\"data/finetune_data/\")\n","checkpoint = \"bert-base-uncased\"\n","tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n","\n","def tokenize_function(example):\n","    return tokenizer(example[\"text\"], padding=True, truncation=True)\n","\n","tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)\n","data_collator = DataCollatorWithPadding(tokenizer=tokenizer) # pad all the examples to the length of the longest element when we batch elements together — dynamic padding."]},{"cell_type":"code","execution_count":34,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18,"status":"ok","timestamp":1700962980121,"user":{"displayName":"Zixiao Wang","userId":"15997148754568851234"},"user_tz":300},"id":"cf_GJiAZRsJ7","outputId":"a45e603d-0442-4a29-d2f2-090619aca940"},"outputs":[{"data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n","        num_rows: 808698\n","    })\n","    validation: Dataset({\n","        features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n","        num_rows: 346585\n","    })\n","    test: Dataset({\n","        features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n","        num_rows: 5791\n","    })\n","})"]},"execution_count":34,"metadata":{},"output_type":"execute_result"}],"source":["tokenized_datasets"]},{"cell_type":"code","execution_count":35,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1700962980121,"user":{"displayName":"Zixiao Wang","userId":"15997148754568851234"},"user_tz":300},"id":"Vix__VrAYQJw","outputId":"1e028d78-a768-4978-e59f-d89977f24590"},"outputs":[{"data":{"text/plain":["Dataset({\n","    features: ['text', 'label'],\n","    num_rows: 808698\n","})"]},"execution_count":35,"metadata":{},"output_type":"execute_result"}],"source":["raw_datasets['train']"]},{"cell_type":"code","execution_count":36,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2400,"status":"ok","timestamp":1700962982517,"user":{"displayName":"Zixiao Wang","userId":"15997148754568851234"},"user_tz":300},"id":"wxMvpJEuYQJx","outputId":"cbf0f82c-1c1d-4ea9-f94e-311346754968"},"outputs":[],"source":["metric = load_metric(\"glue\", \"mrpc\")\n","\n","def compute_metrics(eval_preds):\n","    logits, labels = eval_preds\n","    predictions = np.argmax(logits, axis=-1)\n","    return metric.compute(predictions=predictions, references=labels)"]},{"cell_type":"code","execution_count":37,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1700963958478,"user":{"displayName":"Zixiao Wang","userId":"15997148754568851234"},"user_tz":300},"id":"Vp6LBZQmYxiG"},"outputs":[],"source":["# !pip install transformers[torch]\n","# !pip install accelerate -U"]},{"cell_type":"code","execution_count":38,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1700963005241,"user":{"displayName":"Zixiao Wang","userId":"15997148754568851234"},"user_tz":300},"id":"h3eCd_1YdvaW"},"outputs":[],"source":["# !pip install accelerate==0.24.0"]},{"cell_type":"code","execution_count":39,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1700963005241,"user":{"displayName":"Zixiao Wang","userId":"15997148754568851234"},"user_tz":300},"id":"xzCuNDR6ZlB4","outputId":"fc154a9f-d493-45ad-9f21-b8fefd5446c0"},"outputs":[{"name":"stdout","output_type":"stream","text":["0.24.0\n"]}],"source":["import accelerate\n","print(accelerate.__version__)"]},{"cell_type":"code","execution_count":40,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":84,"referenced_widgets":["95b5255c1f814063b80e70cb846bb697","5de395af82c34a23aa3098467220f540","8ad18caac29e40b79aed70184ee62142","71c8537cfc2f40ec94f4e6a0923e35b9","269dd0645ce744cc9bc3971a35cc2405","32d2a9a4a6c14e9493950097b9951fca","8692ffe0f60a4568806780d0e34f11e3","8f46e5c55db14d7ebd46250510b94fe8","3aa5adbbceda4811a17be59dd790467d","3908d76eb97f42b38a052001ddc9e28c","d1c6d682c07d43c7b47e27714603a014"]},"executionInfo":{"elapsed":9830,"status":"ok","timestamp":1700963015064,"user":{"displayName":"Zixiao Wang","userId":"15997148754568851234"},"user_tz":300},"id":"9VOXyd2JYQJx","outputId":"673e1a7a-3e28-40ee-ca64-627c1942a69d"},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["training_args = TrainingArguments(\n","    output_dir=\"test-trainer\",\n","    evaluation_strategy=\"epoch\",\n","    num_train_epochs=5,\n","    per_device_train_batch_size=16,\n","    per_device_eval_batch_size=128,\n","    # During the first 500 training steps, the learning rate gradually increases from 0 (or a small base rate) to the specified learning rate.\n","    # This gradual increase helps in stabilizing the training process and often leads to better performance, as it prevents the model from making too large updates too quickly.\n","    warmup_steps=500,\n","    weight_decay=0.01,\n","    logging_dir='logs',\n","    logging_steps=10,  # how frequently the training progress is logged\n","    save_strategy=\"epoch\",  # Set save strategy to match evaluation strategy\n","    load_best_model_at_end=True,\n","    metric_for_best_model=\"accuracy\"\n",")\n","model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)\n","\n","trainer = Trainer(\n","    model,\n","    training_args,\n","    train_dataset=tokenized_datasets[\"train\"],\n","    eval_dataset=tokenized_datasets[\"validation\"],\n","    data_collator=data_collator,\n","    tokenizer=tokenizer,\n","    compute_metrics=compute_metrics,\n",")"]},{"cell_type":"code","execution_count":30,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":284},"executionInfo":{"elapsed":376389,"status":"ok","timestamp":1700963392468,"user":{"displayName":"Zixiao Wang","userId":"15997148754568851234"},"user_tz":300},"id":"_y3SU3UfYQJy","outputId":"3aa8305d-3db8-4269-cdcc-8911428c9eaa"},"outputs":[{"name":"stderr","output_type":"stream","text":["  0%|          | 0/361030 [00:17<?, ?it/s]"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"ename":"ValueError","evalue":"The model did not return a loss from the inputs, only the following keys: logits. For reference, the inputs it received are input_ids,token_type_ids,attention_mask.","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[1;32md:\\Cornell\\course\\CS6386\\Analyzing-the-Correlation-Between-Retail-Traders--Sentiments-and-Equity-Market-Movements\\Sentiment_Analysis\\huggingface_modified_example.ipynb Cell 11\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Cornell/course/CS6386/Analyzing-the-Correlation-Between-Retail-Traders--Sentiments-and-Equity-Market-Movements/Sentiment_Analysis/huggingface_modified_example.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain()\n","File \u001b[1;32mc:\\Users\\Steven\\anaconda3\\envs\\stock\\lib\\site-packages\\transformers\\trainer.py:1591\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1589\u001b[0m         hf_hub_utils\u001b[39m.\u001b[39menable_progress_bars()\n\u001b[0;32m   1590\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1591\u001b[0m     \u001b[39mreturn\u001b[39;00m inner_training_loop(\n\u001b[0;32m   1592\u001b[0m         args\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m   1593\u001b[0m         resume_from_checkpoint\u001b[39m=\u001b[39;49mresume_from_checkpoint,\n\u001b[0;32m   1594\u001b[0m         trial\u001b[39m=\u001b[39;49mtrial,\n\u001b[0;32m   1595\u001b[0m         ignore_keys_for_eval\u001b[39m=\u001b[39;49mignore_keys_for_eval,\n\u001b[0;32m   1596\u001b[0m     )\n","File \u001b[1;32mc:\\Users\\Steven\\anaconda3\\envs\\stock\\lib\\site-packages\\transformers\\trainer.py:1892\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   1889\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_handler\u001b[39m.\u001b[39mon_step_begin(args, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol)\n\u001b[0;32m   1891\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maccelerator\u001b[39m.\u001b[39maccumulate(model):\n\u001b[1;32m-> 1892\u001b[0m     tr_loss_step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining_step(model, inputs)\n\u001b[0;32m   1894\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m   1895\u001b[0m     args\u001b[39m.\u001b[39mlogging_nan_inf_filter\n\u001b[0;32m   1896\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[0;32m   1897\u001b[0m     \u001b[39mand\u001b[39;00m (torch\u001b[39m.\u001b[39misnan(tr_loss_step) \u001b[39mor\u001b[39;00m torch\u001b[39m.\u001b[39misinf(tr_loss_step))\n\u001b[0;32m   1898\u001b[0m ):\n\u001b[0;32m   1899\u001b[0m     \u001b[39m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[0;32m   1900\u001b[0m     tr_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m tr_loss \u001b[39m/\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mglobal_step \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_globalstep_last_logged)\n","File \u001b[1;32mc:\\Users\\Steven\\anaconda3\\envs\\stock\\lib\\site-packages\\transformers\\trainer.py:2776\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[1;34m(self, model, inputs)\u001b[0m\n\u001b[0;32m   2773\u001b[0m     \u001b[39mreturn\u001b[39;00m loss_mb\u001b[39m.\u001b[39mreduce_mean()\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m   2775\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompute_loss_context_manager():\n\u001b[1;32m-> 2776\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompute_loss(model, inputs)\n\u001b[0;32m   2778\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mn_gpu \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   2779\u001b[0m     loss \u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mmean()  \u001b[39m# mean() to average on multi-gpu parallel training\u001b[39;00m\n","File \u001b[1;32mc:\\Users\\Steven\\anaconda3\\envs\\stock\\lib\\site-packages\\transformers\\trainer.py:2818\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[1;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[0;32m   2816\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   2817\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(outputs, \u001b[39mdict\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m outputs:\n\u001b[1;32m-> 2818\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   2819\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mThe model did not return a loss from the inputs, only the following keys: \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2820\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m,\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(outputs\u001b[39m.\u001b[39mkeys())\u001b[39m}\u001b[39;00m\u001b[39m. For reference, the inputs it received are \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m,\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(inputs\u001b[39m.\u001b[39mkeys())\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2821\u001b[0m         )\n\u001b[0;32m   2822\u001b[0m     \u001b[39m# We don't use .loss here since the model may return tuples instead of ModelOutput.\u001b[39;00m\n\u001b[0;32m   2823\u001b[0m     loss \u001b[39m=\u001b[39m outputs[\u001b[39m\"\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(outputs, \u001b[39mdict\u001b[39m) \u001b[39melse\u001b[39;00m outputs[\u001b[39m0\u001b[39m]\n","\u001b[1;31mValueError\u001b[0m: The model did not return a loss from the inputs, only the following keys: logits. For reference, the inputs it received are input_ids,token_type_ids,attention_mask."]}],"source":["trainer.train()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"elapsed":1883,"status":"ok","timestamp":1700963394349,"user":{"displayName":"Zixiao Wang","userId":"15997148754568851234"},"user_tz":300},"id":"AT_ucbzzYQJz","outputId":"114574c7-38a9-4e1b-ec06-632bd548d40c"},"outputs":[{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["(408, 2) (408,)\n"]}],"source":["predictions = trainer.predict(tokenized_datasets[\"validation\"])\n","print(predictions.predictions.shape, predictions.label_ids.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"elapsed":11389,"status":"ok","timestamp":1700963530184,"user":{"displayName":"Zixiao Wang","userId":"15997148754568851234"},"user_tz":300},"id":"yOWmQ73hU3x6","outputId":"0028021f-db65-45b6-eb85-56f9bb5d45f4"},"outputs":[{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["(1725, 2) (1725,)\n"]}],"source":["predictions = trainer.predict(tokenized_datasets[\"test\"])\n","print(predictions.predictions.shape, predictions.label_ids.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1058,"status":"ok","timestamp":1700963541269,"user":{"displayName":"Zixiao Wang","userId":"15997148754568851234"},"user_tz":300},"id":"UfdFyGXlU8Wv","outputId":"3159fe96-041c-48b1-ccd6-08d1c923e352"},"outputs":[{"data":{"text/plain":["PredictionOutput(predictions=array([[-4.521311 ,  3.7222323],\n","       [-3.4110165,  2.9014902],\n","       [-4.623328 ,  3.8644013],\n","       ...,\n","       [-4.612073 ,  3.8569236],\n","       [-4.514099 ,  3.6752856],\n","       [-4.265427 ,  3.4012394]], dtype=float32), label_ids=array([1, 1, 1, ..., 0, 1, 1]), metrics={'test_loss': 0.8783374428749084, 'test_accuracy': 0.8417391304347827, 'test_f1': 0.8847615027437737, 'test_runtime': 10.9624, 'test_samples_per_second': 157.356, 'test_steps_per_second': 1.277})"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["predictions"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1700963743112,"user":{"displayName":"Zixiao Wang","userId":"15997148754568851234"},"user_tz":300},"id":"syPX8lkoVuIa","outputId":"39fcba1e-d769-4c7c-ca88-ed7fe16f8a2f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Probabilities:\n"," [[2.6288169e-04 9.9973708e-01]\n"," [1.8101990e-03 9.9818975e-01]\n"," [2.0593787e-04 9.9979407e-01]\n"," ...\n"," [2.0983144e-04 9.9979013e-01]\n"," [2.7750764e-04 9.9972242e-01]\n"," [4.6795682e-04 9.9953210e-01]]\n","Predicted Labels:\n"," [1 1 1 ... 1 1 1]\n"]}],"source":["import numpy as np\n","from scipy.special import softmax\n","\n","# Apply softmax to convert logits to probabilities\n","probabilities = softmax(predictions.predictions, axis=1)\n","\n","# Get the predicted class labels\n","predicted_labels = np.argmax(probabilities, axis=1)\n","\n","print(\"Probabilities:\\n\", probabilities)\n","print(\"Predicted Labels:\\n\", predicted_labels)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.18"},"widgets":{"application/vnd.jupyter.widget-state+json":{"269dd0645ce744cc9bc3971a35cc2405":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"32d2a9a4a6c14e9493950097b9951fca":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3908d76eb97f42b38a052001ddc9e28c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3aa5adbbceda4811a17be59dd790467d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5de395af82c34a23aa3098467220f540":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_32d2a9a4a6c14e9493950097b9951fca","placeholder":"​","style":"IPY_MODEL_8692ffe0f60a4568806780d0e34f11e3","value":"model.safetensors: 100%"}},"71c8537cfc2f40ec94f4e6a0923e35b9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3908d76eb97f42b38a052001ddc9e28c","placeholder":"​","style":"IPY_MODEL_d1c6d682c07d43c7b47e27714603a014","value":" 440M/440M [00:01&lt;00:00, 224MB/s]"}},"8692ffe0f60a4568806780d0e34f11e3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8ad18caac29e40b79aed70184ee62142":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8f46e5c55db14d7ebd46250510b94fe8","max":440449768,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3aa5adbbceda4811a17be59dd790467d","value":440449768}},"8f46e5c55db14d7ebd46250510b94fe8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"95b5255c1f814063b80e70cb846bb697":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5de395af82c34a23aa3098467220f540","IPY_MODEL_8ad18caac29e40b79aed70184ee62142","IPY_MODEL_71c8537cfc2f40ec94f4e6a0923e35b9"],"layout":"IPY_MODEL_269dd0645ce744cc9bc3971a35cc2405"}},"d1c6d682c07d43c7b47e27714603a014":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}
