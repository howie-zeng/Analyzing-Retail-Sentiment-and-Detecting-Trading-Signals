{"cells":[{"cell_type":"markdown","metadata":{"id":"yQQl3Z-a4x44"},"source":["https://huggingface.co/learn/nlp-course/chapter3/3?fw=pt  \n","https://medium.com/nlplanet/bert-finetuning-with-hugging-face-and-training-visualizations-with-tensorboard-46368a57fc97\n"]},{"cell_type":"code","execution_count":219,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1698676182888,"user":{"displayName":"Zixiao Wang","userId":"15997148754568851234"},"user_tz":240},"id":"Sa4HWJ_E4x47","outputId":"ca39bf19-0a64-45dc-be08-cd47bc687054"},"outputs":[],"source":["import os\n","import shutil\n","import numpy as np\n","import pandas as pd\n","from collections import Counter\n","from multiprocessing import Pool\n","from datasets import Dataset, DatasetDict\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix, accuracy_score, f1_score\n","from keras.preprocessing.text import Tokenizer\n","from keras.preprocessing.sequence import pad_sequences\n","\n","import helper_data, helper_model"]},{"cell_type":"markdown","metadata":{},"source":["1: https://www.kaggle.com/code/taufiquesekh/stock-sentiment-analysis"]},{"cell_type":"code","execution_count":220,"metadata":{"id":"qa8Yl4YH4x4-"},"outputs":[],"source":["dataset_filename = {\n","    # '0': (\"training.1600000.processed.noemoticon.csv\", [\"target\", \"ids\", \"date\", \"flag\", \"user\", \"text\"]), # not financial sentiment, not used\n","    '0': (\"gpt.csv\", [\"text,label\"]),\n","    '1': (\"stock_data.csv\", [\"text\", \"target\"]),\n","    '2': (\"nasdaq.csv\", [\"Label\", \"Ticker\", \"Headline\"]), # 0 negative, 1 positive, 2 neural\n","    '3': (\"djia_news copy.csv\", [\"Label\", \"Ticker\", \"Headline\"]), # 0 negative, 1 positive, 2 neural\n","    '4': (\"data-3.csv\", [\"Sentence\", \"Sentiment\"]),\n","    '5': (\"sentiment.csv\", [\"Stock Ticker\", \"Tweet Text\", \"Sentiment\", \"Tweet URL\"]),\n","    '6': ('train_tweet.csv', [\"id\", \"label\", \"tweet\"]),  # 0 positive, 1 negative\n","    '7': ('stock_tweets.csv', [\"Date\", \"Tweet\", \"Stock Name\", \"Company Name\"]),  # 0 positive, 1 negative\n","    '8': ('tweets_labelled.csv', ['id','created_at','text','sentiment'])\n","}"]},{"cell_type":"code","execution_count":221,"metadata":{},"outputs":[],"source":["DATASET_ENCODING = \"ISO-8859-1\""]},{"cell_type":"code","execution_count":222,"metadata":{},"outputs":[],"source":["dataset_path = os.path.join(\"\", \"data\", dataset_filename[\"0\"][0])\n","df0 = pd.read_csv(dataset_path, names=dataset_filename[\"0\"][1], skiprows=[0])\n","df0 = pd.DataFrame(df0)\n","df0[['text', 'label']] = df0['text,label'].str.rsplit(',', n=1, expand=True)\n","df0.drop(columns=['text,label'], inplace=True)\n","decode_map = {0: \"NEGATIVE\", 1: \"POSITIVE\"}\n","df0['target'] = df0['label'].apply(lambda x: decode_map[int(x)])\n","df0.drop(columns=['label'], inplace=True)\n","df0.rename(columns={df0.columns[1]: 'target'}, inplace=True)"]},{"cell_type":"code","execution_count":223,"metadata":{},"outputs":[],"source":["# dataset_path = os.path.join(\"\", \"data\", dataset_filename[\"0\"][0])\n","# df0 = pd.read_csv(dataset_path, encoding=DATASET_ENCODING, names=dataset_filename[\"0\"][1])\n","# decode_map = {0: \"NEGATIVE\", 2: \"NEUTRAL\", 4: \"POSITIVE\"}\n","# df0.target = df0.target.apply(lambda x: decode_map[int(x)])\n","# df0 = df0[['text', 'target']]"]},{"cell_type":"code","execution_count":224,"metadata":{},"outputs":[],"source":["dataset_path = os.path.join(\"\", \"data\", dataset_filename[\"1\"][0])\n","df1 = pd.read_csv(dataset_path, encoding=DATASET_ENCODING)\n","df1 = df1.iloc[:, :-3]\n","decode_map = {-1: \"NEGATIVE\", 1: \"POSITIVE\"}\n","df1['target'] = pd.to_numeric(df1['target'], errors='coerce')\n","df1['target'] = df1['target'].map(decode_map)"]},{"cell_type":"code","execution_count":225,"metadata":{},"outputs":[],"source":["# dataset_path = os.path.join(\"\", \"data\", dataset_filename[\"2\"][0])\n","# df2 = pd.read_csv(dataset_path, encoding=DATASET_ENCODING, names=dataset_filename[\"2\"][1], skiprows=1)\n","# decode_map = {0: \"NEGATIVE\", 2: \"NEUTRAL\", 1: \"POSITIVE\"}\n","# df2['target'] = df2['Label'].apply(lambda x: decode_map[int(x)])\n","# df2 = df2[['Headline', 'target']]\n","# df2.rename(columns={df2.columns[0]: 'text'}, inplace=True)"]},{"cell_type":"code","execution_count":226,"metadata":{},"outputs":[],"source":["# dataset_path = os.path.join(\"\", \"data\", dataset_filename[\"3\"][0])\n","# df3 = pd.read_csv(dataset_path, encoding=DATASET_ENCODING, names=dataset_filename[\"3\"][1], skiprows=1)\n","# decode_map = {0: \"NEGATIVE\", 2: \"NEUTRAL\", 1: \"POSITIVE\"}\n","# df3['target'] = df3['Label'].apply(lambda x: decode_map[int(x)])\n","# df3 = df3[['Headline', 'target']]\n","# df3.rename(columns={df3.columns[0]: 'text'}, inplace=True)"]},{"cell_type":"code","execution_count":227,"metadata":{},"outputs":[],"source":["dataset_path = os.path.join(\"\", \"data\", dataset_filename[\"4\"][0])\n","df4 = pd.read_csv(dataset_path, encoding=DATASET_ENCODING, names=dataset_filename[\"4\"][1], skiprows=1)\n","decode_map = {\"negative\": \"NEGATIVE\", \"neutral\": \"NEUTRAL\", \"positive\": \"POSITIVE\"}\n","df4['target'] = df4['Sentiment'].apply(lambda x: decode_map[x])\n","df4.drop(columns=['Sentiment'], inplace=True)\n","df4.rename(columns={df4.columns[0]: 'text'}, inplace=True)"]},{"cell_type":"code","execution_count":228,"metadata":{},"outputs":[],"source":["dataset_path = os.path.join(\"\", \"data\", dataset_filename[\"5\"][0])\n","df5 = pd.read_csv(dataset_path, encoding=DATASET_ENCODING, names=dataset_filename[\"5\"][1], skiprows=1)\n","decode_map = {\"Negative\": \"NEGATIVE\", \"Positive\": \"POSITIVE\"}\n","df5['target'] = df5['Sentiment'].apply(lambda x: decode_map[x])\n","df5 = df5[['Tweet Text', 'target']]\n","df5.rename(columns={df5.columns[0]: 'text'}, inplace=True)"]},{"cell_type":"code","execution_count":229,"metadata":{},"outputs":[],"source":["# dataset_path = os.path.join(\"\", \"data\", dataset_filename[\"6\"][0])\n","# df6 = pd.read_csv(dataset_path, encoding=DATASET_ENCODING, names=dataset_filename[\"6\"][1], skiprows=1)\n","# decode_map = {0: \"NEGATIVE\", 1: \"POSITIVE\"}\n","# df6['target'] = df6['label'].apply(lambda x: decode_map[int(x)])\n","# df6 = df6[['tweet', 'target']]\n","# df6.rename(columns={df6.columns[0]: 'text'}, inplace=True)"]},{"cell_type":"code","execution_count":230,"metadata":{},"outputs":[],"source":["dataset_path = os.path.join(\"\", \"data\", dataset_filename[\"7\"][0])\n","df7 = pd.read_csv(dataset_path, encoding=DATASET_ENCODING, names=dataset_filename[\"7\"][1], skiprows=1)\n","df7 = df7[['Tweet']]\n","df7.rename(columns={df7.columns[0]: 'text'}, inplace=True)\n","df_test_unlabeled = df7"]},{"cell_type":"code","execution_count":231,"metadata":{},"outputs":[],"source":["dataset_path = os.path.join(\"\", \"data/unorganized\", dataset_filename[\"8\"][0])\n","DATASET_ENCODING = \"utf-8\"  # Replace with the appropriate encoding\n","df8 = pd.read_csv(dataset_path, encoding=DATASET_ENCODING, names=dataset_filename[\"8\"][1], skiprows=1, index_col=None)\n","decode_map = {\"negative\": \"NEGATIVE\", \"neutral\": \"NEUTRAL\", \"positive\": \"POSITIVE\"}\n","df8['target'] = df8['sentiment'].map(decode_map)\n","df8 = df8.dropna(subset=['sentiment'])\n","df8 = df8[['text', 'target']]\n","df_test = df8.dropna(subset=['target'])"]},{"cell_type":"code","execution_count":232,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>RT @RobertBeadles: YoðŸ’¥\\nEnter to WIN 1,000 Mon...</td>\n","      <td>POSITIVE</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>#SriLanka surcharge on fuel removed!\\nâ›½ðŸ“‰\\nThe ...</td>\n","      <td>NEGATIVE</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Net issuance increases to fund fiscal programs...</td>\n","      <td>POSITIVE</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>RT @bentboolean: How much of Amazon's traffic ...</td>\n","      <td>POSITIVE</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>$AMD Ryzen 4000 desktop CPUs looking â€˜greatâ€™ a...</td>\n","      <td>POSITIVE</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1295</th>\n","      <td>#stocks back from the recovery room: https://t...</td>\n","      <td>POSITIVE</td>\n","    </tr>\n","    <tr>\n","      <th>1296</th>\n","      <td>RT @MacroCharts: Breadth â€“ expanding last week...</td>\n","      <td>POSITIVE</td>\n","    </tr>\n","    <tr>\n","      <th>1297</th>\n","      <td>RT @MawsonResource: Rompas-Rajapalot: A Big Ne...</td>\n","      <td>NEUTRAL</td>\n","    </tr>\n","    <tr>\n","      <th>1298</th>\n","      <td>$AAPL $QQQ Top may now be in. https://t.co/iNK...</td>\n","      <td>POSITIVE</td>\n","    </tr>\n","    <tr>\n","      <th>1299</th>\n","      <td>GLG Partners LP short position in HILTON FOOD ...</td>\n","      <td>NEGATIVE</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1300 rows Ã— 2 columns</p>\n","</div>"],"text/plain":["                                                   text    target\n","0     RT @RobertBeadles: YoðŸ’¥\\nEnter to WIN 1,000 Mon...  POSITIVE\n","1     #SriLanka surcharge on fuel removed!\\nâ›½ðŸ“‰\\nThe ...  NEGATIVE\n","2     Net issuance increases to fund fiscal programs...  POSITIVE\n","3     RT @bentboolean: How much of Amazon's traffic ...  POSITIVE\n","4     $AMD Ryzen 4000 desktop CPUs looking â€˜greatâ€™ a...  POSITIVE\n","...                                                 ...       ...\n","1295  #stocks back from the recovery room: https://t...  POSITIVE\n","1296  RT @MacroCharts: Breadth â€“ expanding last week...  POSITIVE\n","1297  RT @MawsonResource: Rompas-Rajapalot: A Big Ne...   NEUTRAL\n","1298  $AAPL $QQQ Top may now be in. https://t.co/iNK...  POSITIVE\n","1299  GLG Partners LP short position in HILTON FOOD ...  NEGATIVE\n","\n","[1300 rows x 2 columns]"]},"execution_count":232,"metadata":{},"output_type":"execute_result"}],"source":["df_test"]},{"cell_type":"code","execution_count":233,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["      label  count\n","0  POSITIVE    528\n","1   NEUTRAL    424\n","2  NEGATIVE    348\n"]}],"source":["target_counts = df_test['target'].value_counts()\n","count_df = pd.DataFrame({\n","    'label': target_counts.index,\n","    'count': target_counts.values\n","})\n","print(count_df)"]},{"cell_type":"code","execution_count":236,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":399,"status":"ok","timestamp":1698677638492,"user":{"displayName":"Zixiao Wang","userId":"15997148754568851234"},"user_tz":240},"id":"YLnvxr-h4x4-","outputId":"18c8a1ec-4e6e-4ca0-d2fc-7f2ed6532cfb"},"outputs":[{"name":"stdout","output_type":"stream","text":["Total number of rows: 14342\n"]}],"source":["total_rows = len(df0) + len(df1) + len(df4) + len(df5) \n","print(\"Total number of rows:\", total_rows)"]},{"cell_type":"code","execution_count":237,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1698677641578,"user":{"displayName":"Zixiao Wang","userId":"15997148754568851234"},"user_tz":240},"id":"yAiqOIcN4x4-","outputId":"e6c65b3c-e5a8-4e7e-e8bb-df2473ea32e6"},"outputs":[{"data":{"text/plain":["(14342, 2)"]},"execution_count":237,"metadata":{},"output_type":"execute_result"}],"source":["df = pd.concat([df0, df1, df4, df5], ignore_index=True)\n","df.shape"]},{"cell_type":"code","execution_count":238,"metadata":{},"outputs":[],"source":["df = helper_data.shuffle_dataframe(df)\n","df = df[df['target'] != \"NEUTRAL\"]\n","df.rename(columns={'target': 'label'}, inplace=True)\n","\n","df_test.rename(columns={'target': 'label'}, inplace=True)\n","\n","df_test_unlabeled.rename(columns={'target': 'label'}, inplace=True)"]},{"cell_type":"code","execution_count":239,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Label</th>\n","      <th>Count</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>POSITIVE</td>\n","      <td>6346</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>NEGATIVE</td>\n","      <td>4811</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      Label  Count\n","0  POSITIVE   6346\n","1  NEGATIVE   4811"]},"execution_count":239,"metadata":{},"output_type":"execute_result"}],"source":["unique_elements_table = df['label'].value_counts().reset_index()\n","unique_elements_table.columns = ['Label', 'Count']\n","unique_elements_table"]},{"cell_type":"code","execution_count":240,"metadata":{},"outputs":[],"source":["# df = df[:100]\n","# df_test = df_test[:8]\n","# df_test_unlabeled = df_test_unlabeled[:10]"]},{"cell_type":"code","execution_count":241,"metadata":{},"outputs":[],"source":["label_mapping = {'POSITIVE': 1, 'NEGATIVE': 0}\n","df = df.dropna(subset=['label'])\n","df['label'] = df['label'].map(label_mapping)\n","\n","label_mapping = {'POSITIVE': 2, 'NEUTRAL': 1, 'NEGATIVE': 0}\n","df_test = df_test.dropna(subset=['label'])\n","df_test['label'] = df_test['label'].map(label_mapping)"]},{"cell_type":"code","execution_count":242,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>6272</th>\n","      <td>JPM bounced off it's fib support level today too.</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>644</th>\n","      <td>$BTC's price is plummeting. Market sentiment i...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4307</th>\n","      <td>Prudential liquidates CM stake... 1st ones off...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>575</th>\n","      <td>Eagerly anticipating $AAPL's product launch ev...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>6634</th>\n","      <td>.user clearly, if (but not until) the 20MA cra...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>14288</th>\n","      <td>#Premarket Top % Gainers:\\r\\n\\r\\n$IDRA $BRDS $...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>$SPY is too volatile right now. Staying out of...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1688</th>\n","      <td>$DIS's stock experiences volatility as the com...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2181</th>\n","      <td>Regulatory scrutiny affects $SQ's stock price ...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>14296</th>\n","      <td>Who else received their $ABBV dividend payment...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>11157 rows Ã— 2 columns</p>\n","</div>"],"text/plain":["                                                    text  label\n","6272   JPM bounced off it's fib support level today too.      0\n","644    $BTC's price is plummeting. Market sentiment i...      0\n","4307   Prudential liquidates CM stake... 1st ones off...      0\n","575    Eagerly anticipating $AAPL's product launch ev...      1\n","6634   .user clearly, if (but not until) the 20MA cra...      0\n","...                                                  ...    ...\n","14288  #Premarket Top % Gainers:\\r\\n\\r\\n$IDRA $BRDS $...      1\n","12     $SPY is too volatile right now. Staying out of...      0\n","1688   $DIS's stock experiences volatility as the com...      0\n","2181   Regulatory scrutiny affects $SQ's stock price ...      0\n","14296  Who else received their $ABBV dividend payment...      1\n","\n","[11157 rows x 2 columns]"]},"execution_count":242,"metadata":{},"output_type":"execute_result"}],"source":["df"]},{"cell_type":"code","execution_count":243,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>RT @RobertBeadles: YoðŸ’¥\\nEnter to WIN 1,000 Mon...</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>#SriLanka surcharge on fuel removed!\\nâ›½ðŸ“‰\\nThe ...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Net issuance increases to fund fiscal programs...</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>RT @bentboolean: How much of Amazon's traffic ...</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>$AMD Ryzen 4000 desktop CPUs looking â€˜greatâ€™ a...</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1295</th>\n","      <td>#stocks back from the recovery room: https://t...</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>1296</th>\n","      <td>RT @MacroCharts: Breadth â€“ expanding last week...</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>1297</th>\n","      <td>RT @MawsonResource: Rompas-Rajapalot: A Big Ne...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1298</th>\n","      <td>$AAPL $QQQ Top may now be in. https://t.co/iNK...</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>1299</th>\n","      <td>GLG Partners LP short position in HILTON FOOD ...</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1300 rows Ã— 2 columns</p>\n","</div>"],"text/plain":["                                                   text  label\n","0     RT @RobertBeadles: YoðŸ’¥\\nEnter to WIN 1,000 Mon...      2\n","1     #SriLanka surcharge on fuel removed!\\nâ›½ðŸ“‰\\nThe ...      0\n","2     Net issuance increases to fund fiscal programs...      2\n","3     RT @bentboolean: How much of Amazon's traffic ...      2\n","4     $AMD Ryzen 4000 desktop CPUs looking â€˜greatâ€™ a...      2\n","...                                                 ...    ...\n","1295  #stocks back from the recovery room: https://t...      2\n","1296  RT @MacroCharts: Breadth â€“ expanding last week...      2\n","1297  RT @MawsonResource: Rompas-Rajapalot: A Big Ne...      1\n","1298  $AAPL $QQQ Top may now be in. https://t.co/iNK...      2\n","1299  GLG Partners LP short position in HILTON FOOD ...      0\n","\n","[1300 rows x 2 columns]"]},"execution_count":243,"metadata":{},"output_type":"execute_result"}],"source":["df_test"]},{"cell_type":"code","execution_count":244,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["   label  count\n","0      1   6346\n","1      0   4811\n"]}],"source":["target_counts = df['label'].value_counts()\n","count_df = pd.DataFrame({\n","    'label': target_counts.index,\n","    'count': target_counts.values\n","})\n","print(count_df)"]},{"cell_type":"code","execution_count":245,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Label</th>\n","      <th>Count</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2</td>\n","      <td>528</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>424</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>348</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Label  Count\n","0      2    528\n","1      1    424\n","2      0    348"]},"execution_count":245,"metadata":{},"output_type":"execute_result"}],"source":["unique_elements_table = df_test['label'].value_counts().reset_index()\n","unique_elements_table.columns = ['Label', 'Count']\n","unique_elements_table"]},{"cell_type":"code","execution_count":246,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Mainstream media has done an amazing job at br...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Tesla delivery estimates are at around 364k fr...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3/ Even if I include 63.0M unvested RSUs as of...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>@RealDanODowd @WholeMarsBlog @Tesla Hahaha why...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>@RealDanODowd @Tesla Stop trying to kill kids,...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>80788</th>\n","      <td>Some of the fastest growing tech stocks on the...</td>\n","    </tr>\n","    <tr>\n","      <th>80789</th>\n","      <td>With earnings on the horizon, here is a quick ...</td>\n","    </tr>\n","    <tr>\n","      <th>80790</th>\n","      <td>Our record delivery results are a testimony of...</td>\n","    </tr>\n","    <tr>\n","      <th>80791</th>\n","      <td>We delivered 10,412 Smart EVs in Sep 2021, rea...</td>\n","    </tr>\n","    <tr>\n","      <th>80792</th>\n","      <td>Why can XPeng P5 deliver outstanding performan...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>80793 rows Ã— 1 columns</p>\n","</div>"],"text/plain":["                                                    text\n","0      Mainstream media has done an amazing job at br...\n","1      Tesla delivery estimates are at around 364k fr...\n","2      3/ Even if I include 63.0M unvested RSUs as of...\n","3      @RealDanODowd @WholeMarsBlog @Tesla Hahaha why...\n","4      @RealDanODowd @Tesla Stop trying to kill kids,...\n","...                                                  ...\n","80788  Some of the fastest growing tech stocks on the...\n","80789  With earnings on the horizon, here is a quick ...\n","80790  Our record delivery results are a testimony of...\n","80791  We delivered 10,412 Smart EVs in Sep 2021, rea...\n","80792  Why can XPeng P5 deliver outstanding performan...\n","\n","[80793 rows x 1 columns]"]},"execution_count":246,"metadata":{},"output_type":"execute_result"}],"source":["df_test_unlabeled"]},{"cell_type":"code","execution_count":247,"metadata":{},"outputs":[],"source":["df = df.reset_index(drop=True)\n","df_test = df_test.reset_index(drop=True)\n","\n","train_dataset = Dataset.from_pandas(df)\n","test_dataset = Dataset.from_pandas(df_test)\n","test_dataset_unlabled = Dataset.from_pandas(df_test_unlabeled)\n","\n","# Create a DatasetDict\n","dataset_dict = DatasetDict({\n","    'train': train_dataset, \n","    'test': test_dataset,\n","    'test_unlabeled': test_dataset_unlabled\n","})"]},{"cell_type":"code","execution_count":248,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Saving the dataset (1/1 shards): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8925/8925 [00:00<00:00, 170701.53 examples/s]\n","Saving the dataset (1/1 shards): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2232/2232 [00:00<00:00, 135157.53 examples/s]\n","Saving the dataset (1/1 shards): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1300/1300 [00:00<00:00, 144267.63 examples/s]\n","Saving the dataset (1/1 shards): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80793/80793 [00:00<00:00, 3087938.79 examples/s]\n"]},{"data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['text', 'label'],\n","        num_rows: 8925\n","    })\n","    validation: Dataset({\n","        features: ['text', 'label'],\n","        num_rows: 2232\n","    })\n","    test: Dataset({\n","        features: ['text', 'label'],\n","        num_rows: 1300\n","    })\n","    test_unlabeled: Dataset({\n","        features: ['text'],\n","        num_rows: 80793\n","    })\n","})"]},"execution_count":248,"metadata":{},"output_type":"execute_result"}],"source":["splitted_datasets = dataset_dict[\"train\"].train_test_split(test_size=0.2)\n","dataset_dict[\"train\"] = splitted_datasets[\"train\"]\n","dataset_dict[\"validation\"] = splitted_datasets[\"test\"]\n","dataset_dict = DatasetDict({\n","    'train': dataset_dict['train'],\n","    'validation': dataset_dict['validation'],\n","    'test': dataset_dict['test'],\n","    'test_unlabeled': dataset_dict['test_unlabeled']\n","})\n","\n","folder = \"data/finetune_data\"\n","if os.path.exists(folder):\n","    shutil.rmtree(folder)\n","dataset_dict.save_to_disk(\"data/finetune_data\")\n","dataset_dict"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.18"}},"nbformat":4,"nbformat_minor":0}
