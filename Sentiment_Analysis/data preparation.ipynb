{"cells":[{"cell_type":"markdown","metadata":{"id":"yQQl3Z-a4x44"},"source":["https://huggingface.co/learn/nlp-course/chapter3/3?fw=pt  \n","https://medium.com/nlplanet/bert-finetuning-with-hugging-face-and-training-visualizations-with-tensorboard-46368a57fc97\n"]},{"cell_type":"code","execution_count":64,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1698676182888,"user":{"displayName":"Zixiao Wang","userId":"15997148754568851234"},"user_tz":240},"id":"Sa4HWJ_E4x47","outputId":"ca39bf19-0a64-45dc-be08-cd47bc687054"},"outputs":[],"source":["import os\n","import shutil\n","import numpy as np\n","import pandas as pd\n","from collections import Counter\n","from multiprocessing import Pool\n","from datasets import Dataset, DatasetDict\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix, accuracy_score, f1_score\n","from keras.preprocessing.text import Tokenizer\n","from keras.preprocessing.sequence import pad_sequences\n","\n","import helper_data, helper_model"]},{"cell_type":"code","execution_count":65,"metadata":{"id":"qa8Yl4YH4x4-"},"outputs":[],"source":["dataset_filename = {\n","    # '0': (\"training.1600000.processed.noemoticon.csv\", [\"target\", \"ids\", \"date\", \"flag\", \"user\", \"text\"]), # not financial sentiment, not used\n","    '0': (\"training.1600000.processed.noemoticon.csv\", [\"target\", \"ids\", \"date\", \"flag\", \"user\", \"text\"]),\n","    '1': (\"stock_data.csv\", [\"text\", \"target\"]),\n","    '2': (\"nasdaq.csv\", [\"Label\", \"Ticker\", \"Headline\"]), # 0 negative, 1 positive, 2 neural\n","    '3': (\"djia_news copy.csv\", [\"Label\", \"Ticker\", \"Headline\"]), # 0 negative, 1 positive, 2 neural\n","    '4': (\"data-3.csv\", [\"Sentence\", \"Sentiment\"]),\n","    '5': (\"sentiment.csv\", [\"Stock Ticker\", \"Tweet Text\", \"Sentiment\", \"Tweet URL\"]),\n","    '6': ('train_tweet.csv', [\"id\", \"label\", \"tweet\"])  # 0 positive, 1 negative\n","}"]},{"cell_type":"code","execution_count":66,"metadata":{"id":"VRiB6JMq4x4-"},"outputs":[],"source":["DATASET_ENCODING = \"ISO-8859-1\"\n","\n","dataset_path = os.path.join(\"\", \"data\", dataset_filename[\"0\"][0])\n","df0 = pd.read_csv(dataset_path, encoding=DATASET_ENCODING, names=dataset_filename[\"0\"][1])\n","decode_map = {0: \"NEGATIVE\", 2: \"NEUTRAL\", 4: \"POSITIVE\"}\n","df0.target = df0.target.apply(lambda x: decode_map[int(x)])\n","df0 = df0[['text', 'target']]\n","\n","dataset_path = os.path.join(\"\", \"data\", dataset_filename[\"1\"][0])   # test dataset\n","df1 = pd.read_csv(dataset_path, encoding=DATASET_ENCODING, names=dataset_filename[\"1\"][1], skiprows=1)\n","df1.rename(columns={df1.columns[0]: 'text'}, inplace=True)\n","decode_map = {-1: \"NEGATIVE\", 1: \"POSITIVE\"}\n","df1.target = df1.target.apply(lambda x: decode_map[int(x)])\n","df_test = df1\n","\n","dataset_path = os.path.join(\"\", \"data\", dataset_filename[\"2\"][0])\n","df2 = pd.read_csv(dataset_path, encoding=DATASET_ENCODING, names=dataset_filename[\"2\"][1], skiprows=1)\n","decode_map = {0: \"NEGATIVE\", 2: \"NEUTRAL\", 1: \"POSITIVE\"}\n","df2['target'] = df2['Label'].apply(lambda x: decode_map[int(x)])\n","df2 = df2[['Headline', 'target']]\n","df2.rename(columns={df2.columns[0]: 'text'}, inplace=True)\n","\n","dataset_path = os.path.join(\"\", \"data\", dataset_filename[\"3\"][0])\n","df3 = pd.read_csv(dataset_path, encoding=DATASET_ENCODING, names=dataset_filename[\"3\"][1], skiprows=1)\n","decode_map = {0: \"NEGATIVE\", 2: \"NEUTRAL\", 1: \"POSITIVE\"}\n","df3['target'] = df3['Label'].apply(lambda x: decode_map[int(x)])\n","df3 = df3[['Headline', 'target']]\n","df3.rename(columns={df3.columns[0]: 'text'}, inplace=True)\n","\n","dataset_path = os.path.join(\"\", \"data\", dataset_filename[\"4\"][0])\n","df4 = pd.read_csv(dataset_path, encoding=DATASET_ENCODING, names=dataset_filename[\"4\"][1], skiprows=1)\n","decode_map = {\"negative\": \"NEGATIVE\", \"neutral\": \"NEUTRAL\", \"positive\": \"POSITIVE\"}\n","df4['target'] = df4['Sentiment'].apply(lambda x: decode_map[x])\n","df4.drop(columns=['Sentiment'], inplace=True)\n","df4.rename(columns={df4.columns[0]: 'text'}, inplace=True)\n","\n","dataset_path = os.path.join(\"\", \"data\", dataset_filename[\"5\"][0])\n","df5 = pd.read_csv(dataset_path, encoding=DATASET_ENCODING, names=dataset_filename[\"5\"][1], skiprows=1)\n","decode_map = {\"Negative\": \"NEGATIVE\", \"Positive\": \"POSITIVE\"}\n","df5['target'] = df5['Sentiment'].apply(lambda x: decode_map[x])\n","df5 = df5[['Tweet Text', 'target']]\n","df5.rename(columns={df5.columns[0]: 'text'}, inplace=True)\n","\n","dataset_path = os.path.join(\"\", \"data\", dataset_filename[\"6\"][0])\n","df6 = pd.read_csv(dataset_path, encoding=DATASET_ENCODING, names=dataset_filename[\"6\"][1], skiprows=1)\n","decode_map = {0: \"POSITIVE\", 1: \"NEGATIVE\"}\n","df6['target'] = df6['label'].apply(lambda x: decode_map[int(x)])\n","df6 = df6[['tweet', 'target']]\n","df6.rename(columns={df6.columns[0]: 'text'}, inplace=True)"]},{"cell_type":"code","execution_count":67,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":399,"status":"ok","timestamp":1698677638492,"user":{"displayName":"Zixiao Wang","userId":"15997148754568851234"},"user_tz":240},"id":"YLnvxr-h4x4-","outputId":"18c8a1ec-4e6e-4ca0-d2fc-7f2ed6532cfb"},"outputs":[{"name":"stdout","output_type":"stream","text":["Total number of rows: 1653866\n"]}],"source":["total_rows = len(df0) + len(df2) + len(df3) + len(df4) + len(df5) + len(df6)\n","print(\"Total number of rows:\", total_rows)"]},{"cell_type":"code","execution_count":68,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1698677641578,"user":{"displayName":"Zixiao Wang","userId":"15997148754568851234"},"user_tz":240},"id":"yAiqOIcN4x4-","outputId":"e6c65b3c-e5a8-4e7e-e8bb-df2473ea32e6"},"outputs":[{"data":{"text/plain":["(53866, 2)"]},"execution_count":68,"metadata":{},"output_type":"execute_result"}],"source":["df = pd.concat([df0, df2, df3, df4, df5, df6], ignore_index=True)\n","df.shape"]},{"cell_type":"code","execution_count":69,"metadata":{},"outputs":[],"source":["df = helper_data.shuffle_dataframe(df)\n","df = df[df['target'] != \"NEUTRAL\"]\n","df.rename(columns={'target': 'label'}, inplace=True)\n","df_test.rename(columns={'target': 'label'}, inplace=True)"]},{"cell_type":"code","execution_count":70,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1698677734386,"user":{"displayName":"Zixiao Wang","userId":"15997148754568851234"},"user_tz":240},"id":"tQvHfSMs_7Yi","outputId":"0fdcaf96-35d5-4102-e16c-33882a2990a5"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>39105</th>\n","      <td>#cuttack #odisha clinches in for an odi agains...</td>\n","      <td>POSITIVE</td>\n","    </tr>\n","    <tr>\n","      <th>48983</th>\n","      <td>#breakfast #holiday #pougal   @ the irish rover</td>\n","      <td>POSITIVE</td>\n","    </tr>\n","    <tr>\n","      <th>45438</th>\n","      <td>@user @user @user @user  and the #teapay #bihe...</td>\n","      <td>NEGATIVE</td>\n","    </tr>\n","    <tr>\n","      <th>31631</th>\n","      <td>after reading about the @user tapings, i am as...</td>\n","      <td>POSITIVE</td>\n","    </tr>\n","    <tr>\n","      <th>7733</th>\n","      <td>Zimbabwe: 'Zim Needs an Independent Central Bank'</td>\n","      <td>NEGATIVE</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>51840</th>\n","      <td>says it all @user you, @user be  . #create #co...</td>\n","      <td>POSITIVE</td>\n","    </tr>\n","    <tr>\n","      <th>44227</th>\n","      <td>@user @user @user @user feeling    #worried.</td>\n","      <td>POSITIVE</td>\n","    </tr>\n","    <tr>\n","      <th>2639</th>\n","      <td>Henan huatai corn germ oil press machine/corn ...</td>\n","      <td>POSITIVE</td>\n","    </tr>\n","    <tr>\n","      <th>39193</th>\n","      <td>remember itÃ°ÂÂÂ  #lost #empire #dreams #su...</td>\n","      <td>POSITIVE</td>\n","    </tr>\n","    <tr>\n","      <th>4193</th>\n","      <td>Irish Prime Minister Brian Cowen was just a fe...</td>\n","      <td>POSITIVE</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>50395 rows × 2 columns</p>\n","</div>"],"text/plain":["                                                    text     label\n","39105  #cuttack #odisha clinches in for an odi agains...  POSITIVE\n","48983   #breakfast #holiday #pougal   @ the irish rover   POSITIVE\n","45438  @user @user @user @user  and the #teapay #bihe...  NEGATIVE\n","31631  after reading about the @user tapings, i am as...  POSITIVE\n","7733   Zimbabwe: 'Zim Needs an Independent Central Bank'  NEGATIVE\n","...                                                  ...       ...\n","51840  says it all @user you, @user be  . #create #co...  POSITIVE\n","44227      @user @user @user @user feeling    #worried.   POSITIVE\n","2639   Henan huatai corn germ oil press machine/corn ...  POSITIVE\n","39193  remember itÃ°ÂÂÂ  #lost #empire #dreams #su...  POSITIVE\n","4193   Irish Prime Minister Brian Cowen was just a fe...  POSITIVE\n","\n","[50395 rows x 2 columns]"]},"execution_count":70,"metadata":{},"output_type":"execute_result"}],"source":["df[:-10]"]},{"cell_type":"code","execution_count":71,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["   label  count\n","0      0  37135\n","1      1  13270\n"]}],"source":["label_mapping = {'POSITIVE': 0, 'NEGATIVE': 1}\n","df['label'] = df['label'].map(label_mapping)\n","df_test['label'] = df_test['label'].map(label_mapping)\n","\n","\n","target_counts = df['label'].value_counts()\n","count_df = pd.DataFrame({\n","    'label': target_counts.index,\n","    'count': target_counts.values\n","})\n","print(count_df)"]},{"cell_type":"code","execution_count":72,"metadata":{},"outputs":[{"data":{"text/plain":["(50405, 2)"]},"execution_count":72,"metadata":{},"output_type":"execute_result"}],"source":["df.shape"]},{"cell_type":"code","execution_count":73,"metadata":{},"outputs":[],"source":["df = df.reset_index(drop=True)\n","\n","train_dataset = Dataset.from_pandas(df)\n","test_dataset = Dataset.from_pandas(df_test)\n","\n","# Create a DatasetDict\n","dataset_dict = DatasetDict({\n","    'train': train_dataset, \n","    'test': test_dataset\n","})"]},{"cell_type":"code","execution_count":74,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Saving the dataset (0/1 shards):  26%|██▌       | 9000/35283 [00:00<00:00, 73528.67 examples/s]"]},{"name":"stderr","output_type":"stream","text":["Saving the dataset (1/1 shards): 100%|██████████| 35283/35283 [00:00<00:00, 98740.77 examples/s] \n","Saving the dataset (1/1 shards): 100%|██████████| 15122/15122 [00:00<00:00, 143797.32 examples/s]\n","Saving the dataset (1/1 shards): 100%|██████████| 5791/5791 [00:00<00:00, 573548.71 examples/s]\n"]},{"data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['text', 'label'],\n","        num_rows: 35283\n","    })\n","    validation: Dataset({\n","        features: ['text', 'label'],\n","        num_rows: 15122\n","    })\n","    test: Dataset({\n","        features: ['text', 'label'],\n","        num_rows: 5791\n","    })\n","})"]},"execution_count":74,"metadata":{},"output_type":"execute_result"}],"source":["splitted_datasets = dataset_dict[\"train\"].train_test_split(test_size=0.3)\n","dataset_dict[\"train\"] = splitted_datasets[\"train\"]\n","dataset_dict[\"validation\"] = splitted_datasets[\"test\"]\n","dataset_dict = DatasetDict({\n","    'train': dataset_dict['train'],\n","    'validation': dataset_dict['validation'],\n","    'test': dataset_dict['test']\n","})\n","\n","\n","folder = \"data/finetune_data\"\n","if os.path.exists(folder):\n","    shutil.rmtree(folder)\n","dataset_dict.save_to_disk(\"data/finetune_data\")\n","dataset_dict"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.18"}},"nbformat":4,"nbformat_minor":0}
