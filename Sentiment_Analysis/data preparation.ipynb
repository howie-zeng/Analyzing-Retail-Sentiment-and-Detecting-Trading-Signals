{"cells":[{"cell_type":"markdown","metadata":{"id":"yQQl3Z-a4x44"},"source":["https://huggingface.co/learn/nlp-course/chapter3/3?fw=pt  \n","https://medium.com/nlplanet/bert-finetuning-with-hugging-face-and-training-visualizations-with-tensorboard-46368a57fc97\n"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1698676182888,"user":{"displayName":"Zixiao Wang","userId":"15997148754568851234"},"user_tz":240},"id":"Sa4HWJ_E4x47","outputId":"ca39bf19-0a64-45dc-be08-cd47bc687054"},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\Steven\\anaconda3\\envs\\stock\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n","[nltk_data] Downloading package wordnet to\n","[nltk_data]     C:\\Users\\Steven\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","[nltk_data] Downloading package stopwords to\n","[nltk_data]     C:\\Users\\Steven\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]}],"source":["import os\n","import shutil\n","import numpy as np\n","import pandas as pd\n","from collections import Counter\n","from multiprocessing import Pool\n","from datasets import Dataset, DatasetDict\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix, accuracy_score, f1_score\n","from keras.preprocessing.text import Tokenizer\n","from keras.preprocessing.sequence import pad_sequences\n","\n","import helper_data, helper_model"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"qa8Yl4YH4x4-"},"outputs":[],"source":["dataset_filename = {\n","    # '0': (\"training.1600000.processed.noemoticon.csv\", [\"target\", \"ids\", \"date\", \"flag\", \"user\", \"text\"]), # not financial sentiment, not used\n","    '0': (\"gpt.csv\", [\"text,label\"]),\n","    '1': (\"stock_data.csv\", [\"text\", \"target\"]),\n","    '2': (\"nasdaq.csv\", [\"Label\", \"Ticker\", \"Headline\"]), # 0 negative, 1 positive, 2 neural\n","    '3': (\"djia_news copy.csv\", [\"Label\", \"Ticker\", \"Headline\"]), # 0 negative, 1 positive, 2 neural\n","    '4': (\"data-3.csv\", [\"Sentence\", \"Sentiment\"]),\n","    '5': (\"sentiment.csv\", [\"Stock Ticker\", \"Tweet Text\", \"Sentiment\", \"Tweet URL\"]),\n","    '6': ('train_tweet.csv', [\"id\", \"label\", \"tweet\"])  # 0 positive, 1 negative\n","}"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["DATASET_ENCODING = \"ISO-8859-1\""]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["dataset_path = os.path.join(\"\", \"data\", dataset_filename[\"0\"][0])\n","df0 = pd.read_csv(dataset_path, names=dataset_filename[\"0\"][1], skiprows=[0])\n","df0 = pd.DataFrame(df0)\n","df0[['text', 'label']] = df0['text,label'].str.rsplit(',', n=1, expand=True)\n","df0.drop(columns=['text,label'], inplace=True)\n","decode_map = {0: \"NEGATIVE\", 1: \"POSITIVE\"}\n","df0['target'] = df0['label'].apply(lambda x: decode_map[int(x)])\n","df0.drop(columns=['label'], inplace=True)\n","df0.rename(columns={df0.columns[1]: 'target'}, inplace=True)"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["# dataset_path = os.path.join(\"\", \"data\", dataset_filename[\"0\"][0])\n","# df0 = pd.read_csv(dataset_path, encoding=DATASET_ENCODING, names=dataset_filename[\"0\"][1])\n","# decode_map = {0: \"NEGATIVE\", 2: \"NEUTRAL\", 4: \"POSITIVE\"}\n","# df0.target = df0.target.apply(lambda x: decode_map[int(x)])\n","# df0 = df0[['text', 'target']]"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["dataset_path = os.path.join(\"\", \"data\", dataset_filename[\"1\"][0])\n","df1 = pd.read_csv(dataset_path, encoding=DATASET_ENCODING)\n","df1 = df1.iloc[:, :-3]\n","decode_map = {-1: \"NEGATIVE\", 1: \"POSITIVE\"}\n","df1['target'] = pd.to_numeric(df1['target'], errors='coerce')\n","df1['target'] = df1['target'].map(decode_map)\n","df_test = df1"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["      label  count\n","0  POSITIVE   3633\n","1  NEGATIVE   2023\n"]}],"source":["target_counts = df_test['target'].value_counts()\n","count_df = pd.DataFrame({\n","    'label': target_counts.index,\n","    'count': target_counts.values\n","})\n","print(count_df)"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["# dataset_path = os.path.join(\"\", \"data\", dataset_filename[\"2\"][0])\n","# df2 = pd.read_csv(dataset_path, encoding=DATASET_ENCODING, names=dataset_filename[\"2\"][1], skiprows=1)\n","# decode_map = {0: \"NEGATIVE\", 2: \"NEUTRAL\", 1: \"POSITIVE\"}\n","# df2['target'] = df2['Label'].apply(lambda x: decode_map[int(x)])\n","# df2 = df2[['Headline', 'target']]\n","# df2.rename(columns={df2.columns[0]: 'text'}, inplace=True)"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["# dataset_path = os.path.join(\"\", \"data\", dataset_filename[\"3\"][0])\n","# df3 = pd.read_csv(dataset_path, encoding=DATASET_ENCODING, names=dataset_filename[\"3\"][1], skiprows=1)\n","# decode_map = {0: \"NEGATIVE\", 2: \"NEUTRAL\", 1: \"POSITIVE\"}\n","# df3['target'] = df3['Label'].apply(lambda x: decode_map[int(x)])\n","# df3 = df3[['Headline', 'target']]\n","# df3.rename(columns={df3.columns[0]: 'text'}, inplace=True)"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["dataset_path = os.path.join(\"\", \"data\", dataset_filename[\"4\"][0])\n","df4 = pd.read_csv(dataset_path, encoding=DATASET_ENCODING, names=dataset_filename[\"4\"][1], skiprows=1)\n","decode_map = {\"negative\": \"NEGATIVE\", \"neutral\": \"NEUTRAL\", \"positive\": \"POSITIVE\"}\n","df4['target'] = df4['Sentiment'].apply(lambda x: decode_map[x])\n","df4.drop(columns=['Sentiment'], inplace=True)\n","df4.rename(columns={df4.columns[0]: 'text'}, inplace=True)"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["dataset_path = os.path.join(\"\", \"data\", dataset_filename[\"5\"][0])\n","df5 = pd.read_csv(dataset_path, encoding=DATASET_ENCODING, names=dataset_filename[\"5\"][1], skiprows=1)\n","decode_map = {\"Negative\": \"NEGATIVE\", \"Positive\": \"POSITIVE\"}\n","df5['target'] = df5['Sentiment'].apply(lambda x: decode_map[x])\n","df5 = df5[['Tweet Text', 'target']]\n","df5.rename(columns={df5.columns[0]: 'text'}, inplace=True)"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["# dataset_path = os.path.join(\"\", \"data\", dataset_filename[\"6\"][0])\n","# df6 = pd.read_csv(dataset_path, encoding=DATASET_ENCODING, names=dataset_filename[\"6\"][1], skiprows=1)\n","# decode_map = {0: \"NEGATIVE\", 1: \"POSITIVE\"}\n","# df6['target'] = df6['label'].apply(lambda x: decode_map[int(x)])\n","# df6 = df6[['tweet', 'target']]\n","# df6.rename(columns={df6.columns[0]: 'text'}, inplace=True)"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":399,"status":"ok","timestamp":1698677638492,"user":{"displayName":"Zixiao Wang","userId":"15997148754568851234"},"user_tz":240},"id":"YLnvxr-h4x4-","outputId":"18c8a1ec-4e6e-4ca0-d2fc-7f2ed6532cfb"},"outputs":[{"name":"stdout","output_type":"stream","text":["Total number of rows: 8531\n"]}],"source":["total_rows = len(df0) + len(df4) + len(df5) \n","print(\"Total number of rows:\", total_rows)"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1698677641578,"user":{"displayName":"Zixiao Wang","userId":"15997148754568851234"},"user_tz":240},"id":"yAiqOIcN4x4-","outputId":"e6c65b3c-e5a8-4e7e-e8bb-df2473ea32e6"},"outputs":[{"data":{"text/plain":["(8531, 2)"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["df = pd.concat([df0, df4, df5], ignore_index=True)\n","df.shape"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["df = helper_data.shuffle_dataframe(df)\n","df = df[df['target'] != \"NEUTRAL\"]\n","df.rename(columns={'target': 'label'}, inplace=True)\n","df_test.rename(columns={'target': 'label'}, inplace=True)"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Label</th>\n","      <th>Count</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>POSITIVE</td>\n","      <td>2713</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>NEGATIVE</td>\n","      <td>2688</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      Label  Count\n","0  POSITIVE   2713\n","1  NEGATIVE   2688"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["unique_elements_table = df['label'].value_counts().reset_index()\n","unique_elements_table.columns = ['Label', 'Count']\n","unique_elements_table"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1698677734386,"user":{"displayName":"Zixiao Wang","userId":"15997148754568851234"},"user_tz":240},"id":"tQvHfSMs_7Yi","outputId":"0fdcaf96-35d5-4102-e16c-33882a2990a5"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>184</th>\n","      <td>$AMZN's cloud division is a cash cow. Expectin...</td>\n","      <td>POSITIVE</td>\n","    </tr>\n","    <tr>\n","      <th>4585</th>\n","      <td>As a result some 20 persons will no longer be ...</td>\n","      <td>NEGATIVE</td>\n","    </tr>\n","    <tr>\n","      <th>8156</th>\n","      <td>If we all short $BLK at the same time thereâ...</td>\n","      <td>NEGATIVE</td>\n","    </tr>\n","    <tr>\n","      <th>7876</th>\n","      <td>expecting  $SPY to close above 205.20 $AAPL</td>\n","      <td>POSITIVE</td>\n","    </tr>\n","    <tr>\n","      <th>6551</th>\n","      <td>Facebook $FB received a Buy rating from Wells ...</td>\n","      <td>POSITIVE</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>4425</th>\n","      <td>In Finland , snow storms brought trees down on...</td>\n","      <td>NEGATIVE</td>\n","    </tr>\n","    <tr>\n","      <th>8505</th>\n","      <td>At first glance $SE numbers look good ð \\r\\...</td>\n","      <td>POSITIVE</td>\n","    </tr>\n","    <tr>\n","      <th>8428</th>\n","      <td>TOP GAINERS \\r\\n\\r\\n$MITQ $BRDS $PPSI $IDRA $AUVI</td>\n","      <td>POSITIVE</td>\n","    </tr>\n","    <tr>\n","      <th>156</th>\n","      <td>$MSFT is a safe haven in uncertain times. Hold...</td>\n","      <td>POSITIVE</td>\n","    </tr>\n","    <tr>\n","      <th>8241</th>\n","      <td>On this day in 1997 Amazon $AMZN went public o...</td>\n","      <td>POSITIVE</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5391 rows × 2 columns</p>\n","</div>"],"text/plain":["                                                   text     label\n","184   $AMZN's cloud division is a cash cow. Expectin...  POSITIVE\n","4585  As a result some 20 persons will no longer be ...  NEGATIVE\n","8156  If we all short $BLK at the same time thereâ...  NEGATIVE\n","7876        expecting  $SPY to close above 205.20 $AAPL  POSITIVE\n","6551  Facebook $FB received a Buy rating from Wells ...  POSITIVE\n","...                                                 ...       ...\n","4425  In Finland , snow storms brought trees down on...  NEGATIVE\n","8505  At first glance $SE numbers look good ð \\r\\...  POSITIVE\n","8428  TOP GAINERS \\r\\n\\r\\n$MITQ $BRDS $PPSI $IDRA $AUVI  POSITIVE\n","156   $MSFT is a safe haven in uncertain times. Hold...  POSITIVE\n","8241  On this day in 1997 Amazon $AMZN went public o...  POSITIVE\n","\n","[5391 rows x 2 columns]"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["df[:-10]"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["   label  count\n","0      1   2713\n","1      0   2688\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Steven\\AppData\\Local\\Temp\\ipykernel_7084\\706084706.py:4: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  df_test['label'] = df_test['label'].map(label_mapping)\n"]}],"source":["label_mapping = {'POSITIVE': 1, 'NEGATIVE': 0}\n","df['label'] = df['label'].map(label_mapping)\n","df_test = df_test.dropna(subset=['label'])\n","df_test['label'] = df_test['label'].map(label_mapping)\n","\n","target_counts = df['label'].value_counts()\n","count_df = pd.DataFrame({\n","    'label': target_counts.index,\n","    'count': target_counts.values\n","})\n","print(count_df)"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>184</th>\n","      <td>$AMZN's cloud division is a cash cow. Expectin...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4585</th>\n","      <td>As a result some 20 persons will no longer be ...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>8156</th>\n","      <td>If we all short $BLK at the same time thereâ...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>7876</th>\n","      <td>expecting  $SPY to close above 205.20 $AAPL</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>6551</th>\n","      <td>Facebook $FB received a Buy rating from Wells ...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>6715</th>\n","      <td>EUR928 ,000 in Q1 2010 6 May 2010 - Finnish te...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>649</th>\n","      <td>Market volatility is taking a toll on my $SPY ...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>6746</th>\n","      <td>The plan is estimated to generate some EUR 5 m...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2147</th>\n","      <td>$DIS's stock takes a hit as the company deals ...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>6391</th>\n","      <td>The company said that its comparable operating...</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5401 rows × 2 columns</p>\n","</div>"],"text/plain":["                                                   text  label\n","184   $AMZN's cloud division is a cash cow. Expectin...      1\n","4585  As a result some 20 persons will no longer be ...      0\n","8156  If we all short $BLK at the same time thereâ...      0\n","7876        expecting  $SPY to close above 205.20 $AAPL      1\n","6551  Facebook $FB received a Buy rating from Wells ...      1\n","...                                                 ...    ...\n","6715  EUR928 ,000 in Q1 2010 6 May 2010 - Finnish te...      1\n","649   Market volatility is taking a toll on my $SPY ...      0\n","6746  The plan is estimated to generate some EUR 5 m...      1\n","2147  $DIS's stock takes a hit as the company deals ...      0\n","6391  The company said that its comparable operating...      0\n","\n","[5401 rows x 2 columns]"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["df"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Kickers on my watchlist XIDE TIT SOQ PNK CPW B...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>user: AAP MOVIE. 55% return for the FEA/GEED i...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>user I'd be afraid to short AMZN - they are lo...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>MNTA Over 12.00</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>OI  Over 21.37</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>5706</th>\n","      <td>Industry body CII said #discoms are likely to ...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5707</th>\n","      <td>#Gold prices slip below Rs 46,000 as #investor...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5708</th>\n","      <td>Workers at Bajaj Auto have agreed to a 10% wag...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>5709</th>\n","      <td>#Sharemarket LIVE: Sensex off dayâs high, up...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>5710</th>\n","      <td>#Sensex, #Nifty climb off day's highs, still u...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5656 rows × 2 columns</p>\n","</div>"],"text/plain":["                                                   text  label\n","0     Kickers on my watchlist XIDE TIT SOQ PNK CPW B...      1\n","1     user: AAP MOVIE. 55% return for the FEA/GEED i...      1\n","2     user I'd be afraid to short AMZN - they are lo...      1\n","3                                     MNTA Over 12.00        1\n","4                                      OI  Over 21.37        1\n","...                                                 ...    ...\n","5706  Industry body CII said #discoms are likely to ...      0\n","5707  #Gold prices slip below Rs 46,000 as #investor...      0\n","5708  Workers at Bajaj Auto have agreed to a 10% wag...      1\n","5709  #Sharemarket LIVE: Sensex off dayâs high, up...      1\n","5710  #Sensex, #Nifty climb off day's highs, still u...      1\n","\n","[5656 rows x 2 columns]"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["df_test"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"data":{"text/plain":["(5401, 2)"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["df.shape"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[],"source":["df = df.reset_index(drop=True)\n","\n","train_dataset = Dataset.from_pandas(df)\n","test_dataset = Dataset.from_pandas(df_test)\n","\n","# Create a DatasetDict\n","dataset_dict = DatasetDict({\n","    'train': train_dataset, \n","    'test': test_dataset\n","})"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Saving the dataset (1/1 shards): 100%|██████████| 4320/4320 [00:00<00:00, 100045.24 examples/s]\n","Saving the dataset (0/1 shards):   0%|          | 0/1081 [00:00<?, ? examples/s]"]},{"name":"stderr","output_type":"stream","text":["Saving the dataset (1/1 shards): 100%|██████████| 1081/1081 [00:00<00:00, 140225.23 examples/s]\n","Saving the dataset (1/1 shards): 100%|██████████| 5656/5656 [00:00<00:00, 585333.55 examples/s]\n"]},{"data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['text', 'label'],\n","        num_rows: 4320\n","    })\n","    validation: Dataset({\n","        features: ['text', 'label'],\n","        num_rows: 1081\n","    })\n","    test: Dataset({\n","        features: ['text', 'label', '__index_level_0__'],\n","        num_rows: 5656\n","    })\n","})"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["splitted_datasets = dataset_dict[\"train\"].train_test_split(test_size=0.2)\n","dataset_dict[\"train\"] = splitted_datasets[\"train\"]\n","dataset_dict[\"validation\"] = splitted_datasets[\"test\"]\n","dataset_dict = DatasetDict({\n","    'train': dataset_dict['train'],\n","    'validation': dataset_dict['validation'],\n","    'test': dataset_dict['test']\n","})\n","\n","folder = \"data/finetune_data\"\n","if os.path.exists(folder):\n","    shutil.rmtree(folder)\n","dataset_dict.save_to_disk(\"data/finetune_data\")\n","dataset_dict"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.18"}},"nbformat":4,"nbformat_minor":0}
