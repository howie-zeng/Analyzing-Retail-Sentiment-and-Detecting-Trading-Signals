{"cells":[{"cell_type":"markdown","metadata":{"id":"yQQl3Z-a4x44"},"source":["https://huggingface.co/learn/nlp-course/chapter3/3?fw=pt  \n","https://medium.com/nlplanet/bert-finetuning-with-hugging-face-and-training-visualizations-with-tensorboard-46368a57fc97\n"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1698676182888,"user":{"displayName":"Zixiao Wang","userId":"15997148754568851234"},"user_tz":240},"id":"Sa4HWJ_E4x47","outputId":"ca39bf19-0a64-45dc-be08-cd47bc687054"},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\Steven\\anaconda3\\envs\\stock\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n","[nltk_data] Downloading package wordnet to\n","[nltk_data]     C:\\Users\\Steven\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","[nltk_data] Downloading package stopwords to\n","[nltk_data]     C:\\Users\\Steven\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]}],"source":["import os\n","import shutil\n","import numpy as np\n","import pandas as pd\n","from collections import Counter\n","from multiprocessing import Pool\n","from datasets import Dataset, DatasetDict\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix, accuracy_score, f1_score\n","from keras.preprocessing.text import Tokenizer\n","from keras.preprocessing.sequence import pad_sequences\n","\n","import helper_data, helper_model"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"qa8Yl4YH4x4-"},"outputs":[],"source":["dataset_filename = {\n","    # '0': (\"training.1600000.processed.noemoticon.csv\", [\"target\", \"ids\", \"date\", \"flag\", \"user\", \"text\"]), # not financial sentiment, not used\n","    '0': (\"gpt.csv\", [\"text,label\"]),\n","    '1': (\"stock_data.csv\", [\"text\", \"target\"]),\n","    '2': (\"nasdaq.csv\", [\"Label\", \"Ticker\", \"Headline\"]), # 0 negative, 1 positive, 2 neural\n","    '3': (\"djia_news copy.csv\", [\"Label\", \"Ticker\", \"Headline\"]), # 0 negative, 1 positive, 2 neural\n","    '4': (\"data-3.csv\", [\"Sentence\", \"Sentiment\"]),\n","    '5': (\"sentiment.csv\", [\"Stock Ticker\", \"Tweet Text\", \"Sentiment\", \"Tweet URL\"]),\n","    '6': ('train_tweet.csv', [\"id\", \"label\", \"tweet\"])  # 0 positive, 1 negative\n","}"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["DATASET_ENCODING = \"ISO-8859-1\""]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["dataset_path = os.path.join(\"\", \"data\", dataset_filename[\"0\"][0])\n","df0 = pd.read_csv(dataset_path, names=dataset_filename[\"0\"][1], skiprows=[0])\n","df0 = pd.DataFrame(df0)\n","df0[['text', 'label']] = df0['text,label'].str.rsplit(',', n=1, expand=True)\n","df0.drop(columns=['text,label'], inplace=True)\n","decode_map = {0: \"NEGATIVE\", 1: \"POSITIVE\"}\n","df0['target'] = df0['label'].apply(lambda x: decode_map[int(x)])\n","df0.drop(columns=['label'], inplace=True)\n","df0.rename(columns={df0.columns[1]: 'target'}, inplace=True)"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["# dataset_path = os.path.join(\"\", \"data\", dataset_filename[\"0\"][0])\n","# df0 = pd.read_csv(dataset_path, encoding=DATASET_ENCODING, names=dataset_filename[\"0\"][1])\n","# decode_map = {0: \"NEGATIVE\", 2: \"NEUTRAL\", 4: \"POSITIVE\"}\n","# df0.target = df0.target.apply(lambda x: decode_map[int(x)])\n","# df0 = df0[['text', 'target']]"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["dataset_path = os.path.join(\"\", \"data\", dataset_filename[\"1\"][0])\n","df1 = pd.read_csv(dataset_path, encoding=DATASET_ENCODING)\n","df1 = df1.iloc[:, :-3]\n","decode_map = {-1: \"NEGATIVE\", 1: \"POSITIVE\"}\n","df1['target'] = pd.to_numeric(df1['target'], errors='coerce')\n","df1['target'] = df1['target'].map(decode_map)\n","df_test = df1"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["      label  count\n","0  POSITIVE   3633\n","1  NEGATIVE   2023\n"]}],"source":["target_counts = df_test['target'].value_counts()\n","count_df = pd.DataFrame({\n","    'label': target_counts.index,\n","    'count': target_counts.values\n","})\n","print(count_df)"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["# dataset_path = os.path.join(\"\", \"data\", dataset_filename[\"2\"][0])\n","# df2 = pd.read_csv(dataset_path, encoding=DATASET_ENCODING, names=dataset_filename[\"2\"][1], skiprows=1)\n","# decode_map = {0: \"NEGATIVE\", 2: \"NEUTRAL\", 1: \"POSITIVE\"}\n","# df2['target'] = df2['Label'].apply(lambda x: decode_map[int(x)])\n","# df2 = df2[['Headline', 'target']]\n","# df2.rename(columns={df2.columns[0]: 'text'}, inplace=True)"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["# dataset_path = os.path.join(\"\", \"data\", dataset_filename[\"3\"][0])\n","# df3 = pd.read_csv(dataset_path, encoding=DATASET_ENCODING, names=dataset_filename[\"3\"][1], skiprows=1)\n","# decode_map = {0: \"NEGATIVE\", 2: \"NEUTRAL\", 1: \"POSITIVE\"}\n","# df3['target'] = df3['Label'].apply(lambda x: decode_map[int(x)])\n","# df3 = df3[['Headline', 'target']]\n","# df3.rename(columns={df3.columns[0]: 'text'}, inplace=True)"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["dataset_path = os.path.join(\"\", \"data\", dataset_filename[\"4\"][0])\n","df4 = pd.read_csv(dataset_path, encoding=DATASET_ENCODING, names=dataset_filename[\"4\"][1], skiprows=1)\n","decode_map = {\"negative\": \"NEGATIVE\", \"neutral\": \"NEUTRAL\", \"positive\": \"POSITIVE\"}\n","df4['target'] = df4['Sentiment'].apply(lambda x: decode_map[x])\n","df4.drop(columns=['Sentiment'], inplace=True)\n","df4.rename(columns={df4.columns[0]: 'text'}, inplace=True)"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["dataset_path = os.path.join(\"\", \"data\", dataset_filename[\"5\"][0])\n","df5 = pd.read_csv(dataset_path, encoding=DATASET_ENCODING, names=dataset_filename[\"5\"][1], skiprows=1)\n","decode_map = {\"Negative\": \"NEGATIVE\", \"Positive\": \"POSITIVE\"}\n","df5['target'] = df5['Sentiment'].apply(lambda x: decode_map[x])\n","df5 = df5[['Tweet Text', 'target']]\n","df5.rename(columns={df5.columns[0]: 'text'}, inplace=True)"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["# dataset_path = os.path.join(\"\", \"data\", dataset_filename[\"6\"][0])\n","# df6 = pd.read_csv(dataset_path, encoding=DATASET_ENCODING, names=dataset_filename[\"6\"][1], skiprows=1)\n","# decode_map = {0: \"NEGATIVE\", 1: \"POSITIVE\"}\n","# df6['target'] = df6['label'].apply(lambda x: decode_map[int(x)])\n","# df6 = df6[['tweet', 'target']]\n","# df6.rename(columns={df6.columns[0]: 'text'}, inplace=True)"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":399,"status":"ok","timestamp":1698677638492,"user":{"displayName":"Zixiao Wang","userId":"15997148754568851234"},"user_tz":240},"id":"YLnvxr-h4x4-","outputId":"18c8a1ec-4e6e-4ca0-d2fc-7f2ed6532cfb"},"outputs":[{"name":"stdout","output_type":"stream","text":["Total number of rows: 7666\n"]}],"source":["total_rows = len(df0) + len(df4) + len(df5) \n","print(\"Total number of rows:\", total_rows)"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1698677641578,"user":{"displayName":"Zixiao Wang","userId":"15997148754568851234"},"user_tz":240},"id":"yAiqOIcN4x4-","outputId":"e6c65b3c-e5a8-4e7e-e8bb-df2473ea32e6"},"outputs":[{"data":{"text/plain":["(7666, 2)"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["df = pd.concat([df0, df4, df5], ignore_index=True)\n","df.shape"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["df = helper_data.shuffle_dataframe(df)\n","df = df[df['target'] != \"NEUTRAL\"]\n","df.rename(columns={'target': 'label'}, inplace=True)\n","df_test.rename(columns={'target': 'label'}, inplace=True)"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Label</th>\n","      <th>Count</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>POSITIVE</td>\n","      <td>2713</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>NEGATIVE</td>\n","      <td>1823</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      Label  Count\n","0  POSITIVE   2713\n","1  NEGATIVE   1823"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["unique_elements_table = df['label'].value_counts().reset_index()\n","unique_elements_table.columns = ['Label', 'Count']\n","unique_elements_table"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1698677734386,"user":{"displayName":"Zixiao Wang","userId":"15997148754568851234"},"user_tz":240},"id":"tQvHfSMs_7Yi","outputId":"0fdcaf96-35d5-4102-e16c-33882a2990a5"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>171</th>\n","      <td>$SPY's volatility is giving me opportunities t...</td>\n","      <td>POSITIVE</td>\n","    </tr>\n","    <tr>\n","      <th>1436</th>\n","      <td>$GOOGL is a short below 740 into the upper BB ...</td>\n","      <td>NEGATIVE</td>\n","    </tr>\n","    <tr>\n","      <th>71</th>\n","      <td>Exited my energy sector position. Locking in p...</td>\n","      <td>POSITIVE</td>\n","    </tr>\n","    <tr>\n","      <th>791</th>\n","      <td>$FORD is stuck in reverse. The legacy automake...</td>\n","      <td>NEGATIVE</td>\n","    </tr>\n","    <tr>\n","      <th>1364</th>\n","      <td>$TSLA recalling pretty much every single model...</td>\n","      <td>NEGATIVE</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>4217</th>\n","      <td>Reed Elsevier share price slides on underwhelm...</td>\n","      <td>NEGATIVE</td>\n","    </tr>\n","    <tr>\n","      <th>4542</th>\n","      <td>The loss for the third quarter of 2007 was EUR...</td>\n","      <td>POSITIVE</td>\n","    </tr>\n","    <tr>\n","      <th>6782</th>\n","      <td>Vaisala also said it expects net sales of EUR ...</td>\n","      <td>POSITIVE</td>\n","    </tr>\n","    <tr>\n","      <th>3255</th>\n","      <td>Phew! So far good $BBRY did not break 10.40 co...</td>\n","      <td>POSITIVE</td>\n","    </tr>\n","    <tr>\n","      <th>7478</th>\n","      <td>$WMT is down more than 6% after cutting guidance</td>\n","      <td>NEGATIVE</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>4526 rows × 2 columns</p>\n","</div>"],"text/plain":["                                                   text     label\n","171   $SPY's volatility is giving me opportunities t...  POSITIVE\n","1436  $GOOGL is a short below 740 into the upper BB ...  NEGATIVE\n","71    Exited my energy sector position. Locking in p...  POSITIVE\n","791   $FORD is stuck in reverse. The legacy automake...  NEGATIVE\n","1364  $TSLA recalling pretty much every single model...  NEGATIVE\n","...                                                 ...       ...\n","4217  Reed Elsevier share price slides on underwhelm...  NEGATIVE\n","4542  The loss for the third quarter of 2007 was EUR...  POSITIVE\n","6782  Vaisala also said it expects net sales of EUR ...  POSITIVE\n","3255  Phew! So far good $BBRY did not break 10.40 co...  POSITIVE\n","7478   $WMT is down more than 6% after cutting guidance  NEGATIVE\n","\n","[4526 rows x 2 columns]"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["df[:-10]"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["   label  count\n","0      1   2713\n","1      0   1823\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Steven\\AppData\\Local\\Temp\\ipykernel_20652\\706084706.py:4: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  df_test['label'] = df_test['label'].map(label_mapping)\n"]}],"source":["label_mapping = {'POSITIVE': 1, 'NEGATIVE': 0}\n","df['label'] = df['label'].map(label_mapping)\n","df_test = df_test.dropna(subset=['label'])\n","df_test['label'] = df_test['label'].map(label_mapping)\n","\n","target_counts = df['label'].value_counts()\n","count_df = pd.DataFrame({\n","    'label': target_counts.index,\n","    'count': target_counts.values\n","})\n","print(count_df)"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>171</th>\n","      <td>$SPY's volatility is giving me opportunities t...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1436</th>\n","      <td>$GOOGL is a short below 740 into the upper BB ...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>71</th>\n","      <td>Exited my energy sector position. Locking in p...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>791</th>\n","      <td>$FORD is stuck in reverse. The legacy automake...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1364</th>\n","      <td>$TSLA recalling pretty much every single model...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>925</th>\n","      <td>Disappointment looms as $MSFT's stock price fa...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1014</th>\n","      <td>Challenges persist for $BBBY, and turnaround e...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5888</th>\n","      <td>Operating profit totaled EUR 6.7 mn , down fro...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3672</th>\n","      <td>2 Turnaround Buys For 2016? BHP Billiton plc A...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>6567</th>\n","      <td>According to M-real 's CEO , Mikko Helander , ...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>4536 rows × 2 columns</p>\n","</div>"],"text/plain":["                                                   text  label\n","171   $SPY's volatility is giving me opportunities t...      1\n","1436  $GOOGL is a short below 740 into the upper BB ...      0\n","71    Exited my energy sector position. Locking in p...      1\n","791   $FORD is stuck in reverse. The legacy automake...      0\n","1364  $TSLA recalling pretty much every single model...      0\n","...                                                 ...    ...\n","925   Disappointment looms as $MSFT's stock price fa...      0\n","1014  Challenges persist for $BBBY, and turnaround e...      0\n","5888  Operating profit totaled EUR 6.7 mn , down fro...      0\n","3672  2 Turnaround Buys For 2016? BHP Billiton plc A...      1\n","6567  According to M-real 's CEO , Mikko Helander , ...      1\n","\n","[4536 rows x 2 columns]"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["df"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Kickers on my watchlist XIDE TIT SOQ PNK CPW B...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>user: AAP MOVIE. 55% return for the FEA/GEED i...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>user I'd be afraid to short AMZN - they are lo...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>MNTA Over 12.00</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>OI  Over 21.37</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>5706</th>\n","      <td>Industry body CII said #discoms are likely to ...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5707</th>\n","      <td>#Gold prices slip below Rs 46,000 as #investor...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5708</th>\n","      <td>Workers at Bajaj Auto have agreed to a 10% wag...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>5709</th>\n","      <td>#Sharemarket LIVE: Sensex off dayâs high, up...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>5710</th>\n","      <td>#Sensex, #Nifty climb off day's highs, still u...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5656 rows × 2 columns</p>\n","</div>"],"text/plain":["                                                   text  label\n","0     Kickers on my watchlist XIDE TIT SOQ PNK CPW B...      1\n","1     user: AAP MOVIE. 55% return for the FEA/GEED i...      1\n","2     user I'd be afraid to short AMZN - they are lo...      1\n","3                                     MNTA Over 12.00        1\n","4                                      OI  Over 21.37        1\n","...                                                 ...    ...\n","5706  Industry body CII said #discoms are likely to ...      0\n","5707  #Gold prices slip below Rs 46,000 as #investor...      0\n","5708  Workers at Bajaj Auto have agreed to a 10% wag...      1\n","5709  #Sharemarket LIVE: Sensex off dayâs high, up...      1\n","5710  #Sensex, #Nifty climb off day's highs, still u...      1\n","\n","[5656 rows x 2 columns]"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["df_test"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"data":{"text/plain":["(4536, 2)"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["df.shape"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[],"source":["df = df.reset_index(drop=True)\n","\n","train_dataset = Dataset.from_pandas(df)\n","test_dataset = Dataset.from_pandas(df_test)\n","\n","# Create a DatasetDict\n","dataset_dict = DatasetDict({\n","    'train': train_dataset, \n","    'test': test_dataset\n","})"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Saving the dataset (1/1 shards): 100%|██████████| 3628/3628 [00:00<00:00, 123409.90 examples/s]\n","Saving the dataset (1/1 shards): 100%|██████████| 908/908 [00:00<00:00, 62857.79 examples/s]\n","Saving the dataset (1/1 shards): 100%|██████████| 5656/5656 [00:00<00:00, 542723.42 examples/s]\n"]},{"data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['text', 'label'],\n","        num_rows: 3628\n","    })\n","    validation: Dataset({\n","        features: ['text', 'label'],\n","        num_rows: 908\n","    })\n","    test: Dataset({\n","        features: ['text', 'label', '__index_level_0__'],\n","        num_rows: 5656\n","    })\n","})"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["splitted_datasets = dataset_dict[\"train\"].train_test_split(test_size=0.2)\n","dataset_dict[\"train\"] = splitted_datasets[\"train\"]\n","dataset_dict[\"validation\"] = splitted_datasets[\"test\"]\n","dataset_dict = DatasetDict({\n","    'train': dataset_dict['train'],\n","    'validation': dataset_dict['validation'],\n","    'test': dataset_dict['test']\n","})\n","\n","folder = \"data/finetune_data\"\n","if os.path.exists(folder):\n","    shutil.rmtree(folder)\n","dataset_dict.save_to_disk(\"data/finetune_data\")\n","dataset_dict"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.18"}},"nbformat":4,"nbformat_minor":0}
