{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"4TVkFuf0fVWk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1701188977706,"user_tz":300,"elapsed":1636,"user":{"displayName":"Zixiao Wang","userId":"15997148754568851234"}},"outputId":"efcd11d8-6a8f-483e-8feb-af3c810f78af"},"outputs":[{"output_type":"stream","name":"stdout","text":["datasets is already installed.\n"]}],"source":["import importlib\n","\n","package_name = \"datasets\"\n","\n","try:\n","    importlib.import_module(package_name)\n","    print(f\"{package_name} is already installed.\")\n","except ImportError:\n","    print(f\"{package_name} is not installed. Installing it now...\")\n","    !pip install {package_name}\n","    print(f\"{package_name} has been successfully installed.\")"]},{"cell_type":"code","source":["import importlib\n","\n","package_name = \"accelerate\"\n","\n","try:\n","    importlib.import_module(package_name)\n","    print(f\"{package_name} is already installed.\")\n","except ImportError:\n","    print(f\"{package_name} is not installed. Installing it now...\")\n","    !pip install {package_name}\n","    print(f\"{package_name} has been successfully installed.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HNViMcmQNPXM","executionInfo":{"status":"ok","timestamp":1701188983438,"user_tz":300,"elapsed":5737,"user":{"displayName":"Zixiao Wang","userId":"15997148754568851234"}},"outputId":"ba1bbe02-c2b1-48ca-e802-87fcd0791d9a"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["accelerate is already installed.\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from scipy.special import softmax\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","\n","from transformers import Trainer\n","from transformers import TrainingArguments\n","from transformers import AutoModelForSequenceClassification\n","from transformers import AutoModelForPreTraining\n","from transformers import BertTokenizer, AutoTokenizer, DataCollatorWithPadding, BertForSequenceClassification\n","\n","from datasets import load_metric\n","from datasets import load_dataset\n","from datasets import load_from_disk\n","\n","import torch\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"],"metadata":{"id":"a3RHK3olFvWx","executionInfo":{"status":"ok","timestamp":1701188991686,"user_tz":300,"elapsed":8277,"user":{"displayName":"Zixiao Wang","userId":"15997148754568851234"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount(\"/content/drive\")\n","\n","%cd \"/content/drive/MyDrive/6386\"\n","\n","# from colab.file_utils import load_required\n","# load_required(force_reinstall_pytorch=True)"],"metadata":{"id":"YpDhZ8GTA-cx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1701188992848,"user_tz":300,"elapsed":1200,"user":{"displayName":"Zixiao Wang","userId":"15997148754568851234"}},"outputId":"46a5eacc-28df-4f40-bc37-bac71cb6470b"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/MyDrive/6386\n"]}]},{"cell_type":"code","execution_count":5,"metadata":{"id":"WPtOlhLO96nG","executionInfo":{"status":"ok","timestamp":1701188992849,"user_tz":300,"elapsed":9,"user":{"displayName":"Zixiao Wang","userId":"15997148754568851234"}}},"outputs":[],"source":["import torch\n","torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"xP6V5YrDvRrk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1701188993032,"user_tz":300,"elapsed":190,"user":{"displayName":"Zixiao Wang","userId":"15997148754568851234"}},"outputId":"17ad2777-d4b8-4c67-cf02-26172b755ae5"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/6386\n"]}],"source":["import os\n","print(os.getcwd())"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"UHtD8mn9fWil","executionInfo":{"status":"ok","timestamp":1701188993032,"user_tz":300,"elapsed":5,"user":{"displayName":"Zixiao Wang","userId":"15997148754568851234"}}},"outputs":[],"source":["# !pip install datasets"]},{"cell_type":"code","source":["# # Hugging Face pre-trained\n","# tokenizer = AutoTokenizer.from_pretrained(\"nlpaueb/sec-bert-base\")\n","# model = AutoModelForPreTraining.from_pretrained(\"nlpaueb/sec-bert-base\")"],"metadata":{"id":"7nQOYjBucHTD","executionInfo":{"status":"ok","timestamp":1701188993033,"user_tz":300,"elapsed":5,"user":{"displayName":"Zixiao Wang","userId":"15997148754568851234"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["# checkpoint = \"bert-base-uncased\"\n","# checkpoint = \"bert-base-cased\"\n","checkpoint = \"distilbert-base-uncased\"\n","# model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)\n","model = BertForSequenceClassification.from_pretrained(checkpoint, num_labels=2).to(device)\n","\n","tokenizer = AutoTokenizer.from_pretrained(checkpoint)"],"metadata":{"id":"3wNS6HtubCKW","executionInfo":{"status":"ok","timestamp":1701189005894,"user_tz":300,"elapsed":12866,"user":{"displayName":"Zixiao Wang","userId":"15997148754568851234"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"0bcddfdd-e855-40fa-d584-46a6144f5744"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stderr","text":["You are using a model of type distilbert to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.7.output.dense.weight', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.3.attention.self.query.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.output.dense.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'classifier.bias', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.2.output.dense.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.1.output.dense.bias', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.4.output.dense.weight', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.1.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.bias', 'pooler.dense.bias', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.2.attention.self.query.weight', 'classifier.weight', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.7.intermediate.dense.bias', 'embeddings.token_type_embeddings.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.0.output.dense.weight', 'embeddings.position_embeddings.weight', 'encoder.layer.2.output.dense.bias', 'embeddings.LayerNorm.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.10.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.8.attention.self.key.bias', 'embeddings.word_embeddings.weight', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.3.output.dense.bias', 'encoder.layer.4.output.dense.bias', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.7.output.dense.bias', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.8.attention.self.key.weight', 'pooler.dense.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.2.attention.output.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}]},{"cell_type":"code","execution_count":10,"metadata":{"id":"f4tLexhaYQJt","executionInfo":{"status":"ok","timestamp":1701189009858,"user_tz":300,"elapsed":3971,"user":{"displayName":"Zixiao Wang","userId":"15997148754568851234"}},"colab":{"base_uri":"https://localhost:8080/","height":113,"referenced_widgets":["5a4a235053694084bc528583c3c570bd","a13c8ce2e03d4b87aa98a02fe7804cb1","0ac7e69f342349f09fc90718dbc5fd24","e7efe1da964f4605a4d911ed01f6137b","78719195f954442586be2d5f8e8b988b","ef295efbbdc34b0c8abaca045b222650","3e20f105197f42e8b1644bd444803295","ef703c711a094f41b0323b75fee5ee36","e1d83e60ae644a78875a72018ab81cca","aa0c5f2c95534433b3b04af37ece83b6","80db962fa5b34bc8a3097f5c8147c8f3","56c79b8a33a244eaa7a624c140aa8944","5cfdf5f3b1ec4f52af860ec55d418a6f","cbde999b58b949218abe6cb2f080121f","f956d54ad79b4c53a75ecb83b1427a11","5de3ea4199bb46dd8e47f948fe18c47d","ad795f3e390347a68749a6bf11eaa494","b54a74d3fbee42a589e1f4a245af18a9","9f6107928d8f487792d65ea99830f43f","d5195f79fa5e4b70899a0550c94223bc","7e38c092f9f747658a321415f109d557","1de4cf43246143f388f32f2a6ae38765","06384d82ba1e4bc8b7bdcb71fad303fa","8b1a2759de524608a509a4553fbcab37","f2261491d7aa4af496ec44e4e6e9d58e","88572c89e8524e2e9de8446985ddf331","1eb527bddba6412b9539749f19fc6bf4","fb74a56fa33b4ecb92f7ac2513ed0db3","effb82cd9de843f698b2aefcde4e357b","d3887caf7ee34e4b8a713733f8a5eeb2","7c246424094b4852bf6450f776484acf","1da0a19bf7d54205940a762ff463b8d6","913f664ab02840738deb0428e07e284f"]},"outputId":"9bab1908-8f9c-471a-afff-c1af2063d323"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/8 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5a4a235053694084bc528583c3c570bd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/2 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"56c79b8a33a244eaa7a624c140aa8944"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/8 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"06384d82ba1e4bc8b7bdcb71fad303fa"}},"metadata":{}}],"source":["raw_datasets = load_from_disk(\"finetune_data\")\n","\n","def tokenize_function(example):\n","    return tokenizer(example[\"text\"], padding=True, truncation=True)\n","\n","tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)\n","data_collator = DataCollatorWithPadding(tokenizer=tokenizer) # pad all the examples to the length of the longest element when we batch elements together â€” dynamic padding."]},{"cell_type":"code","execution_count":11,"metadata":{"id":"cf_GJiAZRsJ7","executionInfo":{"status":"ok","timestamp":1701189009859,"user_tz":300,"elapsed":18,"user":{"displayName":"Zixiao Wang","userId":"15997148754568851234"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"7c71a438-6ea9-406f-bfdd-37af43e2b7aa"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['text', 'label', 'input_ids', 'attention_mask'],\n","        num_rows: 8\n","    })\n","    validation: Dataset({\n","        features: ['text', 'label', 'input_ids', 'attention_mask'],\n","        num_rows: 2\n","    })\n","    test: Dataset({\n","        features: ['text', 'label', 'input_ids', 'attention_mask'],\n","        num_rows: 8\n","    })\n","    test_unlabeled: Dataset({\n","        features: ['text', 'input_ids', 'attention_mask'],\n","        num_rows: 10\n","    })\n","})"]},"metadata":{},"execution_count":11}],"source":["tokenized_datasets"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"Z_E_Yiv1-S1d","executionInfo":{"status":"ok","timestamp":1701189009860,"user_tz":300,"elapsed":15,"user":{"displayName":"Zixiao Wang","userId":"15997148754568851234"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"fe55c4f4-cd68-48af-ae2a-6539f26d8211"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[\"Both the net sales and operating profit were record high in the company 's history .\",\n"," 'RT @joemccann the correleation between the dollar index and $SPY is simply amazing. $DX finds support, $SPY retreats like clockwork',\n"," 'Sales of security and system packaging increased slightly .',\n"," 'NaturalGas Settles At 3-year Low $DBO $BNO  http://stks.co/d27qX',\n"," 'Good Morrrning Retail!!! Todays Plays: $BBIG $PPSI $MARA $SOFI $SLDB $DIDI $AMC $BRDS Good Luck Ã°\\x9f\\x8d\\x80',\n"," \"18 May 2010 - Finnish electronics producer Elcoteq SE HEL : ELQAV said today that it has signed an extensive cooperation agreement on industrialisation , manufacturing , distribution and after-market services for mobile phones with Japan 's Sharp TYO : 6753 .\",\n"," \"$AAPL's CEO just made a major announcement. What's the impact on the stock? ????\",\n"," 'Now glancing at $SE which was once called the Amazon of SE Asia with a gaming arm. Gaming falling off hard as people go out more, but e-commerce and payments have good growth. Issue is costs growing faster so you end up with this. Stock likely up cause been beaten down so hard']"]},"metadata":{},"execution_count":12}],"source":["tokenized_datasets['train']['text'][:10]"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"wxMvpJEuYQJx","executionInfo":{"status":"ok","timestamp":1701189010486,"user_tz":300,"elapsed":637,"user":{"displayName":"Zixiao Wang","userId":"15997148754568851234"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"4a619eb1-8416-4f3b-84c3-3fc92f22b349"},"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-13-093e3287862a>:1: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n","  metric = load_metric(\"glue\", \"mrpc\")\n"]}],"source":["metric = load_metric(\"glue\", \"mrpc\")\n","\n","def compute_metrics(eval_preds):\n","    logits, labels = eval_preds\n","    predictions = np.argmax(logits, axis=-1)\n","    return metric.compute(predictions=predictions, references=labels)"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"Vp6LBZQmYxiG","executionInfo":{"status":"ok","timestamp":1701189026973,"user_tz":300,"elapsed":16493,"user":{"displayName":"Zixiao Wang","userId":"15997148754568851234"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"aa5567b0-86b5-41b3-dac0-76fbd4ae68fe"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (4.35.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.13.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.19.4)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.31.0)\n","Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.15.0)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.4.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.66.1)\n","Requirement already satisfied: torch!=1.12.0,>=1.10 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.1.0+cu118)\n","Requirement already satisfied: accelerate>=0.20.3 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.24.1)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.20.3->transformers[torch]) (5.9.5)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers[torch]) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers[torch]) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (3.1.2)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (2.1.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2023.7.22)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch!=1.12.0,>=1.10->transformers[torch]) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch!=1.12.0,>=1.10->transformers[torch]) (1.3.0)\n","Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.24.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.2)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n","Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.1.0+cu118)\n","Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.19.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.13.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.2)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.1.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2023.7.22)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"]}],"source":["!pip install transformers[torch]\n","!pip install accelerate -U"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"xzCuNDR6ZlB4","executionInfo":{"status":"ok","timestamp":1701189026974,"user_tz":300,"elapsed":8,"user":{"displayName":"Zixiao Wang","userId":"15997148754568851234"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"bcd49c9f-377e-4935-9709-be3dae0d87d6"},"outputs":[{"output_type":"stream","name":"stdout","text":["0.24.1\n"]}],"source":["import accelerate\n","print(accelerate.__version__)"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"9VOXyd2JYQJx","executionInfo":{"status":"ok","timestamp":1701189026974,"user_tz":300,"elapsed":6,"user":{"displayName":"Zixiao Wang","userId":"15997148754568851234"}}},"outputs":[],"source":["training_args = TrainingArguments(\n","    output_dir=\"test-trainer\",\n","    evaluation_strategy=\"epoch\",\n","    num_train_epochs=3,\n","    per_device_train_batch_size=16,\n","    per_device_eval_batch_size=256,\n","    # During the first 500 training steps, the learning rate gradually increases from 0 (or a small base rate) to the specified learning rate.\n","    # This gradual increase helps in stabilizing the training process and often leads to better performance, as it prevents the model from making too large updates too quickly.\n","    warmup_steps=500,\n","    weight_decay=0.01,\n","    logging_dir='logs',\n","    logging_steps=10,  # how frequently the training progress is logged\n","    save_strategy=\"epoch\",  # Set save strategy to \"epoch\" to save both best and last models\n","    load_best_model_at_end=True,\n","    metric_for_best_model=\"accuracy\",\n","    report_to=\"none\",  # disable wandb\n","    # fp16=True,  # Enable mixed precision training\n",")\n","\n","trainer = Trainer(\n","    model,\n","    training_args,\n","    train_dataset=tokenized_datasets[\"train\"],\n","    eval_dataset=tokenized_datasets[\"validation\"],\n","    data_collator=data_collator,\n","    tokenizer=tokenizer,\n","    compute_metrics=compute_metrics,\n",")"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"_y3SU3UfYQJy","colab":{"base_uri":"https://localhost:8080/","height":241},"outputId":"311f071d-34c0-483a-8790-3d4cc77273e2","executionInfo":{"status":"ok","timestamp":1701189081278,"user_tz":300,"elapsed":54310,"user":{"displayName":"Zixiao Wang","userId":"15997148754568851234"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [3/3 00:51, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.701206</td>\n","      <td>0.500000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>No log</td>\n","      <td>0.699938</td>\n","      <td>0.500000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>No log</td>\n","      <td>0.697644</td>\n","      <td>0.500000</td>\n","      <td>0.000000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=3, training_loss=0.7668245633443197, metrics={'train_runtime': 53.5981, 'train_samples_per_second': 0.448, 'train_steps_per_second': 0.056, 'total_flos': 764666504640.0, 'train_loss': 0.7668245633443197, 'epoch': 3.0})"]},"metadata":{},"execution_count":17}],"source":["trainer.train()"]},{"cell_type":"code","source":["output_dir = \"saved_model\"\n","os.makedirs(output_dir, exist_ok=True)\n","\n","# Save the best model and the last model\n","trainer.save_model(output_dir)\n","tokenizer.save_pretrained(output_dir)"],"metadata":{"id":"44lbB6o0Rv4j","executionInfo":{"status":"ok","timestamp":1701189084737,"user_tz":300,"elapsed":3478,"user":{"displayName":"Zixiao Wang","userId":"15997148754568851234"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"71c3fd90-a496-4e7b-eb2f-a3a29fcc0237"},"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["('saved_model/tokenizer_config.json',\n"," 'saved_model/special_tokens_map.json',\n"," 'saved_model/vocab.txt',\n"," 'saved_model/added_tokens.json',\n"," 'saved_model/tokenizer.json')"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["tokenized_datasets[\"test\"]['text']"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fvNA_6titUO9","executionInfo":{"status":"ok","timestamp":1701189084737,"user_tz":300,"elapsed":10,"user":{"displayName":"Zixiao Wang","userId":"15997148754568851234"}},"outputId":"9652c848-7ea5-4707-98a5-1f232b111cee"},"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Kickers on my watchlist XIDE TIT SOQ PNK CPW BPZ AJ  trade method 1 or method 2, see prev posts',\n"," 'user: AAP MOVIE. 55% return for the FEA/GEED indicator just 15 trades for the year.  AWESOME.  ',\n"," \"user I'd be afraid to short AMZN - they are looking like a near-monopoly in eBooks and infrastructure-as-a-service\",\n"," 'MNTA Over 12.00  ',\n"," 'OI  Over 21.37  ',\n"," 'PGNX  Over 3.04  ',\n"," 'AAP - user if so then the current downtrend will break. Otherwise just a short-term correction in med-term downtrend.',\n"," \"Monday's relative weakness. NYX WIN TIE TAP ICE INT BMC AON C CHK BIIB  \"]"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","execution_count":20,"metadata":{"id":"yOWmQ73hU3x6","executionInfo":{"status":"ok","timestamp":1701189085381,"user_tz":300,"elapsed":649,"user":{"displayName":"Zixiao Wang","userId":"15997148754568851234"}},"colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"22168040-1c6e-49de-fe3c-3dc4dd960883"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["(8, 2) (8,)\n"]}],"source":["predictions = trainer.predict(tokenized_datasets[\"test\"])\n","print(predictions.predictions.shape, predictions.label_ids.shape)"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"UfdFyGXlU8Wv","executionInfo":{"status":"ok","timestamp":1701189085381,"user_tz":300,"elapsed":19,"user":{"displayName":"Zixiao Wang","userId":"15997148754568851234"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"69d329a6-730f-4ba1-f065-e9d9b2f1bf93"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["PredictionOutput(predictions=array([[-0.01037394, -0.23742616],\n","       [-0.0082894 , -0.3313913 ],\n","       [-0.05561402, -0.33699414],\n","       [ 0.07951535, -0.13008961],\n","       [ 0.08491139, -0.23141351],\n","       [ 0.07152186, -0.17986003],\n","       [-0.02059496, -0.27584192],\n","       [ 0.00868374, -0.2967829 ]], dtype=float32), label_ids=array([1, 1, 1, 1, 1, 1, 0, 0]), metrics={'test_loss': 0.7680109739303589, 'test_accuracy': 0.25, 'test_f1': 0.0, 'test_runtime': 0.1214, 'test_samples_per_second': 65.917, 'test_steps_per_second': 8.24})"]},"metadata":{},"execution_count":21}],"source":["predictions"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"syPX8lkoVuIa","executionInfo":{"status":"ok","timestamp":1701189085382,"user_tz":300,"elapsed":15,"user":{"displayName":"Zixiao Wang","userId":"15997148754568851234"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"e604d128-b9bc-454f-94f0-20ea0289f445"},"outputs":[{"output_type":"stream","name":"stdout","text":["Probabilities:\n"," [[0.5565204  0.44347957]\n"," [0.58008003 0.41991997]\n"," [0.56988454 0.43011543]\n"," [0.5522102  0.44778976]\n"," [0.5784283  0.42157164]\n"," [0.5625166  0.4374834 ]\n"," [0.5634675  0.43653244]\n"," [0.57577837 0.42422166]]\n","Predicted Labels:\n"," [0 0 0 0 0 0 0 0]\n"]}],"source":["probabilities = softmax(predictions.predictions, axis=1)\n","predicted_labels = np.argmax(probabilities, axis=1)\n","\n","print(\"Probabilities:\\n\", probabilities)\n","print(\"Predicted Labels:\\n\", predicted_labels)"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"fcpHYFOPwxnw","executionInfo":{"status":"ok","timestamp":1701189085568,"user_tz":300,"elapsed":197,"user":{"displayName":"Zixiao Wang","userId":"15997148754568851234"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"bcf0f219-acd9-4df2-c099-3850e8b3f593"},"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.25\n","Precision: 0.0\n","Recall: 0.25\n","F1 Score: 0.1\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}],"source":["true_labels = tokenized_datasets[\"test\"][\"label\"]\n","\n","accuracy = accuracy_score(true_labels, predicted_labels)\n","precision = precision_score(true_labels, predicted_labels)\n","recall = recall_score(true_labels, predicted_labels, average='weighted')\n","f1 = f1_score(true_labels, predicted_labels, average='weighted')\n","\n","print(\"Accuracy:\", accuracy)\n","print(\"Precision:\", precision)\n","print(\"Recall:\", recall)\n","print(\"F1 Score:\", f1)"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"wsWYpKLm-S1i","executionInfo":{"status":"ok","timestamp":1701189085568,"user_tz":300,"elapsed":10,"user":{"displayName":"Zixiao Wang","userId":"15997148754568851234"}}},"outputs":[],"source":["# helper_model.print_wrong_classifications(predicted_labels, true_labels, raw_datasets['test'])"]},{"cell_type":"markdown","source":["Use the saved model to predit on the unlabled testing data."],"metadata":{"id":"Z7A2dW2NUeAW"}},{"cell_type":"code","source":["# Define the path to the saved model directory\n","saved_model_dir = \"saved_model\"\n","\n","# Load the saved tokenizer\n","tokenizer = BertTokenizer.from_pretrained(saved_model_dir)\n","\n","# Load the saved model\n","model = BertForSequenceClassification.from_pretrained(saved_model_dir)\n","model"],"metadata":{"id":"-hDBmOXJTwSG","executionInfo":{"status":"ok","timestamp":1701189089811,"user_tz":300,"elapsed":4251,"user":{"displayName":"Zixiao Wang","userId":"15997148754568851234"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"8accad71-c911-4799-c965-3010951c94ae"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stderr","text":["The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n","The tokenizer class you load from this checkpoint is 'DistilBertTokenizer'. \n","The class this function is called from is 'BertTokenizer'.\n"]},{"output_type":"execute_result","data":{"text/plain":["BertForSequenceClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0-11): 12 x BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",")"]},"metadata":{},"execution_count":26}]},{"cell_type":"code","source":["trainer = Trainer(model=model)\n","predictions = trainer.predict(tokenized_datasets[\"test_unlabeled\"])\n","# Apply softmax to convert logits to probabilities\n","probabilities = softmax(predictions.predictions, axis=1)\n","\n","# Get the predicted class labels\n","predicted_labels = np.argmax(probabilities, axis=1)\n","\n","print(\"Probabilities:\\n\", probabilities)\n","print(\"Predicted Labels:\\n\", predicted_labels)"],"metadata":{"id":"Gm_UGCaeUcv4","executionInfo":{"status":"ok","timestamp":1701189171368,"user_tz":300,"elapsed":609,"user":{"displayName":"Zixiao Wang","userId":"15997148754568851234"}},"colab":{"base_uri":"https://localhost:8080/","height":243},"outputId":"7759a36c-0c58-40f4-b670-53518d859d9e"},"execution_count":29,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Probabilities:\n"," [[0.58869964 0.41130036]\n"," [0.5823089  0.4176911 ]\n"," [0.5820477  0.41795227]\n"," [0.57150066 0.42849937]\n"," [0.5641721  0.4358279 ]\n"," [0.57707214 0.42292783]\n"," [0.5798263  0.42017373]\n"," [0.5812539  0.4187461 ]\n"," [0.56878144 0.43121853]\n"," [0.56459635 0.43540365]]\n","Predicted Labels:\n"," [0 0 0 0 0 0 0 0 0 0]\n"]}]},{"cell_type":"code","source":["result_df = pd.DataFrame({\n","    'text': raw_datasets['test_unlabeled']['text'],\n","    'Predicted_Labels': predicted_labels,\n","    'Probability_Class_0': probabilities[:, 0],\n","    'Probability_Class_1': probabilities[:, 1], # 2 classes\n","})\n","\n","output_csv_path = \"predictions.csv\"\n","result_df.to_csv(output_csv_path, index=False)\n","print(f\"Predictions have been saved to {output_csv_path}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LyKSq4pmx-ko","executionInfo":{"status":"ok","timestamp":1701189687249,"user_tz":300,"elapsed":132,"user":{"displayName":"Zixiao Wang","userId":"15997148754568851234"}},"outputId":"f129fef4-bc70-412a-9b78-c8f1c26cae1d"},"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["Predictions have been saved to predictions.csv\n"]}]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.18"},"widgets":{"application/vnd.jupyter.widget-state+json":{"5a4a235053694084bc528583c3c570bd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a13c8ce2e03d4b87aa98a02fe7804cb1","IPY_MODEL_0ac7e69f342349f09fc90718dbc5fd24","IPY_MODEL_e7efe1da964f4605a4d911ed01f6137b"],"layout":"IPY_MODEL_78719195f954442586be2d5f8e8b988b"}},"a13c8ce2e03d4b87aa98a02fe7804cb1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ef295efbbdc34b0c8abaca045b222650","placeholder":"â€‹","style":"IPY_MODEL_3e20f105197f42e8b1644bd444803295","value":"Map: 100%"}},"0ac7e69f342349f09fc90718dbc5fd24":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ef703c711a094f41b0323b75fee5ee36","max":8,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e1d83e60ae644a78875a72018ab81cca","value":8}},"e7efe1da964f4605a4d911ed01f6137b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_aa0c5f2c95534433b3b04af37ece83b6","placeholder":"â€‹","style":"IPY_MODEL_80db962fa5b34bc8a3097f5c8147c8f3","value":" 8/8 [00:00&lt;00:00, 56.98 examples/s]"}},"78719195f954442586be2d5f8e8b988b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ef295efbbdc34b0c8abaca045b222650":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3e20f105197f42e8b1644bd444803295":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ef703c711a094f41b0323b75fee5ee36":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e1d83e60ae644a78875a72018ab81cca":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"aa0c5f2c95534433b3b04af37ece83b6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"80db962fa5b34bc8a3097f5c8147c8f3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"56c79b8a33a244eaa7a624c140aa8944":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5cfdf5f3b1ec4f52af860ec55d418a6f","IPY_MODEL_cbde999b58b949218abe6cb2f080121f","IPY_MODEL_f956d54ad79b4c53a75ecb83b1427a11"],"layout":"IPY_MODEL_5de3ea4199bb46dd8e47f948fe18c47d"}},"5cfdf5f3b1ec4f52af860ec55d418a6f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ad795f3e390347a68749a6bf11eaa494","placeholder":"â€‹","style":"IPY_MODEL_b54a74d3fbee42a589e1f4a245af18a9","value":"Map: 100%"}},"cbde999b58b949218abe6cb2f080121f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9f6107928d8f487792d65ea99830f43f","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d5195f79fa5e4b70899a0550c94223bc","value":2}},"f956d54ad79b4c53a75ecb83b1427a11":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7e38c092f9f747658a321415f109d557","placeholder":"â€‹","style":"IPY_MODEL_1de4cf43246143f388f32f2a6ae38765","value":" 2/2 [00:00&lt;00:00, 25.75 examples/s]"}},"5de3ea4199bb46dd8e47f948fe18c47d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ad795f3e390347a68749a6bf11eaa494":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b54a74d3fbee42a589e1f4a245af18a9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9f6107928d8f487792d65ea99830f43f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d5195f79fa5e4b70899a0550c94223bc":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7e38c092f9f747658a321415f109d557":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1de4cf43246143f388f32f2a6ae38765":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"06384d82ba1e4bc8b7bdcb71fad303fa":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8b1a2759de524608a509a4553fbcab37","IPY_MODEL_f2261491d7aa4af496ec44e4e6e9d58e","IPY_MODEL_88572c89e8524e2e9de8446985ddf331"],"layout":"IPY_MODEL_1eb527bddba6412b9539749f19fc6bf4"}},"8b1a2759de524608a509a4553fbcab37":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fb74a56fa33b4ecb92f7ac2513ed0db3","placeholder":"â€‹","style":"IPY_MODEL_effb82cd9de843f698b2aefcde4e357b","value":"Map: 100%"}},"f2261491d7aa4af496ec44e4e6e9d58e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d3887caf7ee34e4b8a713733f8a5eeb2","max":8,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7c246424094b4852bf6450f776484acf","value":8}},"88572c89e8524e2e9de8446985ddf331":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1da0a19bf7d54205940a762ff463b8d6","placeholder":"â€‹","style":"IPY_MODEL_913f664ab02840738deb0428e07e284f","value":" 8/8 [00:00&lt;00:00, 91.66 examples/s]"}},"1eb527bddba6412b9539749f19fc6bf4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fb74a56fa33b4ecb92f7ac2513ed0db3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"effb82cd9de843f698b2aefcde4e357b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d3887caf7ee34e4b8a713733f8a5eeb2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7c246424094b4852bf6450f776484acf":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1da0a19bf7d54205940a762ff463b8d6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"913f664ab02840738deb0428e07e284f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}