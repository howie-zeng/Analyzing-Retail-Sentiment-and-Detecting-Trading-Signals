{"cells":[{"cell_type":"code","execution_count":27,"metadata":{"executionInfo":{"elapsed":6970,"status":"ok","timestamp":1700962975288,"user":{"displayName":"Zixiao Wang","userId":"15997148754568851234"},"user_tz":300},"id":"4TVkFuf0fVWk"},"outputs":[],"source":["import numpy as np\n","\n","from transformers import Trainer\n","from transformers import TrainingArguments\n","from transformers import AutoModelForSequenceClassification\n","\n","from datasets import load_metric\n","from datasets import load_dataset\n","from transformers import AutoTokenizer, DataCollatorWithPadding"]},{"cell_type":"code","execution_count":28,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1700962975289,"user":{"displayName":"Zixiao Wang","userId":"15997148754568851234"},"user_tz":300},"id":"UHtD8mn9fWil"},"outputs":[],"source":["# !pip install datasets"]},{"cell_type":"code","execution_count":29,"metadata":{"executionInfo":{"elapsed":4835,"status":"ok","timestamp":1700962980121,"user":{"displayName":"Zixiao Wang","userId":"15997148754568851234"},"user_tz":300},"id":"f4tLexhaYQJt"},"outputs":[],"source":["raw_datasets = load_dataset(\"glue\", \"mrpc\")\n","checkpoint = \"bert-base-uncased\"\n","tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n","\n","\n","def tokenize_function(example):\n","    return tokenizer(example[\"sentence1\"], example[\"sentence2\"], padding=True, truncation=True)\n","\n","\n","tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)\n","data_collator = DataCollatorWithPadding(tokenizer=tokenizer) # pad all the examples to the length of the longest element when we batch elements together â€” dynamic padding."]},{"cell_type":"code","execution_count":30,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18,"status":"ok","timestamp":1700962980121,"user":{"displayName":"Zixiao Wang","userId":"15997148754568851234"},"user_tz":300},"id":"cf_GJiAZRsJ7","outputId":"a45e603d-0442-4a29-d2f2-090619aca940"},"outputs":[{"data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['sentence1', 'sentence2', 'label', 'idx', 'input_ids', 'token_type_ids', 'attention_mask'],\n","        num_rows: 3668\n","    })\n","    validation: Dataset({\n","        features: ['sentence1', 'sentence2', 'label', 'idx', 'input_ids', 'token_type_ids', 'attention_mask'],\n","        num_rows: 408\n","    })\n","    test: Dataset({\n","        features: ['sentence1', 'sentence2', 'label', 'idx', 'input_ids', 'token_type_ids', 'attention_mask'],\n","        num_rows: 1725\n","    })\n","})"]},"execution_count":30,"metadata":{},"output_type":"execute_result"}],"source":["tokenized_datasets"]},{"cell_type":"code","execution_count":31,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1700962980121,"user":{"displayName":"Zixiao Wang","userId":"15997148754568851234"},"user_tz":300},"id":"Vix__VrAYQJw","outputId":"1e028d78-a768-4978-e59f-d89977f24590"},"outputs":[{"data":{"text/plain":["{'sentence1': ['Amrozi accused his brother , whom he called \" the witness \" , of deliberately distorting his evidence .',\n","  \"Yucaipa owned Dominick 's before selling the chain to Safeway in 1998 for $ 2.5 billion .\",\n","  'They had published an advertisement on the Internet on June 10 , offering the cargo for sale , he added .',\n","  'Around 0335 GMT , Tab shares were up 19 cents , or 4.4 % , at A $ 4.56 , having earlier set a record high of A $ 4.57 .',\n","  'The stock rose $ 2.11 , or about 11 percent , to close Friday at $ 21.51 on the New York Stock Exchange .',\n","  'Revenue in the first quarter of the year dropped 15 percent from the same period a year earlier .',\n","  'The Nasdaq had a weekly gain of 17.27 , or 1.2 percent , closing at 1,520.15 on Friday .',\n","  'The DVD-CCA then appealed to the state Supreme Court .',\n","  'That compared with $ 35.18 million , or 24 cents per share , in the year-ago period .',\n","  'Shares of Genentech , a much larger company with several products on the market , rose more than 2 percent .'],\n"," 'sentence2': ['Referring to him as only \" the witness \" , Amrozi accused his brother of deliberately distorting his evidence .',\n","  \"Yucaipa bought Dominick 's in 1995 for $ 693 million and sold it to Safeway for $ 1.8 billion in 1998 .\",\n","  \"On June 10 , the ship 's owners had published an advertisement on the Internet , offering the explosives for sale .\",\n","  'Tab shares jumped 20 cents , or 4.6 % , to set a record closing high at A $ 4.57 .',\n","  'PG & E Corp. shares jumped $ 1.63 or 8 percent to $ 21.03 on the New York Stock Exchange on Friday .',\n","  \"With the scandal hanging over Stewart 's company , revenue the first quarter of the year dropped 15 percent from the same period a year earlier .\",\n","  'The tech-laced Nasdaq Composite .IXIC rallied 30.46 points , or 2.04 percent , to 1,520.15 .',\n","  'The DVD CCA appealed that decision to the U.S. Supreme Court .',\n","  'Earnings were affected by a non-recurring $ 8 million tax benefit in the year-ago period .',\n","  'Shares of Xoma fell 16 percent in early trade , while shares of Genentech , a much larger company with several products on the market , were up 2 percent .'],\n"," 'label': [1, 0, 1, 0, 1, 1, 0, 1, 0, 0],\n"," 'idx': [0, 1, 2, 3, 4, 5, 6, 7, 8, 10]}"]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["raw_datasets"]},{"cell_type":"code","execution_count":32,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2400,"status":"ok","timestamp":1700962982517,"user":{"displayName":"Zixiao Wang","userId":"15997148754568851234"},"user_tz":300},"id":"wxMvpJEuYQJx","outputId":"cbf0f82c-1c1d-4ea9-f94e-311346754968"},"outputs":[],"source":["metric = load_metric(\"glue\", \"mrpc\")\n","\n","def compute_metrics(eval_preds):\n","    logits, labels = eval_preds\n","    predictions = np.argmax(logits, axis=-1)\n","    return metric.compute(predictions=predictions, references=labels)"]},{"cell_type":"code","execution_count":33,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1700963958478,"user":{"displayName":"Zixiao Wang","userId":"15997148754568851234"},"user_tz":300},"id":"Vp6LBZQmYxiG"},"outputs":[],"source":["# !pip install transformers[torch]\n","# !pip install accelerate -U"]},{"cell_type":"code","execution_count":34,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1700963005241,"user":{"displayName":"Zixiao Wang","userId":"15997148754568851234"},"user_tz":300},"id":"h3eCd_1YdvaW"},"outputs":[],"source":["# !pip install accelerate==0.24.0"]},{"cell_type":"code","execution_count":35,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1700963005241,"user":{"displayName":"Zixiao Wang","userId":"15997148754568851234"},"user_tz":300},"id":"xzCuNDR6ZlB4","outputId":"fc154a9f-d493-45ad-9f21-b8fefd5446c0"},"outputs":[{"name":"stdout","output_type":"stream","text":["0.24.0\n"]}],"source":["import accelerate\n","print(accelerate.__version__)"]},{"cell_type":"code","execution_count":36,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":84,"referenced_widgets":["95b5255c1f814063b80e70cb846bb697","5de395af82c34a23aa3098467220f540","8ad18caac29e40b79aed70184ee62142","71c8537cfc2f40ec94f4e6a0923e35b9","269dd0645ce744cc9bc3971a35cc2405","32d2a9a4a6c14e9493950097b9951fca","8692ffe0f60a4568806780d0e34f11e3","8f46e5c55db14d7ebd46250510b94fe8","3aa5adbbceda4811a17be59dd790467d","3908d76eb97f42b38a052001ddc9e28c","d1c6d682c07d43c7b47e27714603a014"]},"executionInfo":{"elapsed":9830,"status":"ok","timestamp":1700963015064,"user":{"displayName":"Zixiao Wang","userId":"15997148754568851234"},"user_tz":300},"id":"9VOXyd2JYQJx","outputId":"673e1a7a-3e28-40ee-ca64-627c1942a69d"},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["training_args = TrainingArguments(\n","    output_dir=\"test-trainer\",\n","    evaluation_strategy=\"epoch\",\n","    num_train_epochs=5,\n","    per_device_train_batch_size=16,\n","    per_device_eval_batch_size=128,\n","    # During the first 500 training steps, the learning rate gradually increases from 0 (or a small base rate) to the specified learning rate.\n","    # This gradual increase helps in stabilizing the training process and often leads to better performance, as it prevents the model from making too large updates too quickly.\n","    warmup_steps=500,\n","    weight_decay=0.01,\n","    logging_dir='logs',\n","    logging_steps=10,  # how frequently the training progress is logged\n","    save_strategy=\"epoch\",  # Set save strategy to match evaluation strategy\n","    load_best_model_at_end=True,\n","    metric_for_best_model=\"accuracy\"\n",")\n","model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)\n","\n","trainer = Trainer(\n","    model,\n","    training_args,\n","    train_dataset=tokenized_datasets[\"train\"],\n","    eval_dataset=tokenized_datasets[\"validation\"],\n","    data_collator=data_collator,\n","    tokenizer=tokenizer,\n","    compute_metrics=compute_metrics,\n",")"]},{"cell_type":"code","execution_count":37,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":284},"executionInfo":{"elapsed":376389,"status":"ok","timestamp":1700963392468,"user":{"displayName":"Zixiao Wang","userId":"15997148754568851234"},"user_tz":300},"id":"_y3SU3UfYQJy","outputId":"3aa8305d-3db8-4269-cdcc-8911428c9eaa"},"outputs":[{"name":"stderr","output_type":"stream","text":["  1%|          | 8/1150 [04:14<10:04:41, 31.77s/it]\n","  0%|          | 0/1150 [00:00<?, ?it/s]You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","  0%|          | 1/1150 [00:08<2:48:39,  8.81s/it]"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[1;32md:\\Cornell\\course\\CS6386\\Analyzing-the-Correlation-Between-Retail-Traders--Sentiments-and-Equity-Market-Movements\\Sentiment_Analysis\\huggingface_example.ipynb Cell 11\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Cornell/course/CS6386/Analyzing-the-Correlation-Between-Retail-Traders--Sentiments-and-Equity-Market-Movements/Sentiment_Analysis/huggingface_example.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain()\n","File \u001b[1;32mc:\\Users\\Steven\\anaconda3\\envs\\stock\\lib\\site-packages\\transformers\\trainer.py:1591\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1589\u001b[0m         hf_hub_utils\u001b[39m.\u001b[39menable_progress_bars()\n\u001b[0;32m   1590\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1591\u001b[0m     \u001b[39mreturn\u001b[39;00m inner_training_loop(\n\u001b[0;32m   1592\u001b[0m         args\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m   1593\u001b[0m         resume_from_checkpoint\u001b[39m=\u001b[39;49mresume_from_checkpoint,\n\u001b[0;32m   1594\u001b[0m         trial\u001b[39m=\u001b[39;49mtrial,\n\u001b[0;32m   1595\u001b[0m         ignore_keys_for_eval\u001b[39m=\u001b[39;49mignore_keys_for_eval,\n\u001b[0;32m   1596\u001b[0m     )\n","File \u001b[1;32mc:\\Users\\Steven\\anaconda3\\envs\\stock\\lib\\site-packages\\transformers\\trainer.py:1971\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   1969\u001b[0m     optimizer_was_run \u001b[39m=\u001b[39m scale_before \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m scale_after\n\u001b[0;32m   1970\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1971\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptimizer\u001b[39m.\u001b[39;49mstep()\n\u001b[0;32m   1972\u001b[0m     optimizer_was_run \u001b[39m=\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maccelerator\u001b[39m.\u001b[39moptimizer_step_was_skipped\n\u001b[0;32m   1974\u001b[0m \u001b[39mif\u001b[39;00m optimizer_was_run:\n\u001b[0;32m   1975\u001b[0m     \u001b[39m# Delay optimizer scheduling until metrics are generated\u001b[39;00m\n","File \u001b[1;32mc:\\Users\\Steven\\anaconda3\\envs\\stock\\lib\\site-packages\\accelerate\\optimizer.py:145\u001b[0m, in \u001b[0;36mAcceleratedOptimizer.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    143\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_accelerate_step_called \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    144\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 145\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptimizer\u001b[39m.\u001b[39;49mstep(closure)\n","File \u001b[1;32mc:\\Users\\Steven\\anaconda3\\envs\\stock\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:68\u001b[0m, in \u001b[0;36mLRScheduler.__init__.<locals>.with_counter.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     66\u001b[0m instance\u001b[39m.\u001b[39m_step_count \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m     67\u001b[0m wrapped \u001b[39m=\u001b[39m func\u001b[39m.\u001b[39m\u001b[39m__get__\u001b[39m(instance, \u001b[39mcls\u001b[39m)\n\u001b[1;32m---> 68\u001b[0m \u001b[39mreturn\u001b[39;00m wrapped(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n","File \u001b[1;32mc:\\Users\\Steven\\anaconda3\\envs\\stock\\lib\\site-packages\\torch\\optim\\optimizer.py:373\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    368\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    369\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[0;32m    370\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m}\u001b[39;00m\u001b[39m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[39m{\u001b[39;00mresult\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    371\u001b[0m             )\n\u001b[1;32m--> 373\u001b[0m out \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    374\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    376\u001b[0m \u001b[39m# call optimizer step post hooks\u001b[39;00m\n","File \u001b[1;32mc:\\Users\\Steven\\anaconda3\\envs\\stock\\lib\\site-packages\\torch\\optim\\optimizer.py:76\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     74\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefaults[\u001b[39m'\u001b[39m\u001b[39mdifferentiable\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m     75\u001b[0m     torch\u001b[39m.\u001b[39m_dynamo\u001b[39m.\u001b[39mgraph_break()\n\u001b[1;32m---> 76\u001b[0m     ret \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     77\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     78\u001b[0m     torch\u001b[39m.\u001b[39m_dynamo\u001b[39m.\u001b[39mgraph_break()\n","File \u001b[1;32mc:\\Users\\Steven\\anaconda3\\envs\\stock\\lib\\site-packages\\torch\\optim\\adamw.py:184\u001b[0m, in \u001b[0;36mAdamW.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    171\u001b[0m     beta1, beta2 \u001b[39m=\u001b[39m group[\u001b[39m\"\u001b[39m\u001b[39mbetas\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m    173\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_group(\n\u001b[0;32m    174\u001b[0m         group,\n\u001b[0;32m    175\u001b[0m         params_with_grad,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    181\u001b[0m         state_steps,\n\u001b[0;32m    182\u001b[0m     )\n\u001b[1;32m--> 184\u001b[0m     adamw(\n\u001b[0;32m    185\u001b[0m         params_with_grad,\n\u001b[0;32m    186\u001b[0m         grads,\n\u001b[0;32m    187\u001b[0m         exp_avgs,\n\u001b[0;32m    188\u001b[0m         exp_avg_sqs,\n\u001b[0;32m    189\u001b[0m         max_exp_avg_sqs,\n\u001b[0;32m    190\u001b[0m         state_steps,\n\u001b[0;32m    191\u001b[0m         amsgrad\u001b[39m=\u001b[39;49mamsgrad,\n\u001b[0;32m    192\u001b[0m         beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[0;32m    193\u001b[0m         beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[0;32m    194\u001b[0m         lr\u001b[39m=\u001b[39;49mgroup[\u001b[39m\"\u001b[39;49m\u001b[39mlr\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m    195\u001b[0m         weight_decay\u001b[39m=\u001b[39;49mgroup[\u001b[39m\"\u001b[39;49m\u001b[39mweight_decay\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m    196\u001b[0m         eps\u001b[39m=\u001b[39;49mgroup[\u001b[39m\"\u001b[39;49m\u001b[39meps\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m    197\u001b[0m         maximize\u001b[39m=\u001b[39;49mgroup[\u001b[39m\"\u001b[39;49m\u001b[39mmaximize\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m    198\u001b[0m         foreach\u001b[39m=\u001b[39;49mgroup[\u001b[39m\"\u001b[39;49m\u001b[39mforeach\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m    199\u001b[0m         capturable\u001b[39m=\u001b[39;49mgroup[\u001b[39m\"\u001b[39;49m\u001b[39mcapturable\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m    200\u001b[0m         differentiable\u001b[39m=\u001b[39;49mgroup[\u001b[39m\"\u001b[39;49m\u001b[39mdifferentiable\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m    201\u001b[0m         fused\u001b[39m=\u001b[39;49mgroup[\u001b[39m\"\u001b[39;49m\u001b[39mfused\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m    202\u001b[0m         grad_scale\u001b[39m=\u001b[39;49m\u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mgrad_scale\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m    203\u001b[0m         found_inf\u001b[39m=\u001b[39;49m\u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mfound_inf\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m    204\u001b[0m     )\n\u001b[0;32m    206\u001b[0m \u001b[39mreturn\u001b[39;00m loss\n","File \u001b[1;32mc:\\Users\\Steven\\anaconda3\\envs\\stock\\lib\\site-packages\\torch\\optim\\adamw.py:335\u001b[0m, in \u001b[0;36madamw\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[0;32m    332\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    333\u001b[0m     func \u001b[39m=\u001b[39m _single_tensor_adamw\n\u001b[1;32m--> 335\u001b[0m func(\n\u001b[0;32m    336\u001b[0m     params,\n\u001b[0;32m    337\u001b[0m     grads,\n\u001b[0;32m    338\u001b[0m     exp_avgs,\n\u001b[0;32m    339\u001b[0m     exp_avg_sqs,\n\u001b[0;32m    340\u001b[0m     max_exp_avg_sqs,\n\u001b[0;32m    341\u001b[0m     state_steps,\n\u001b[0;32m    342\u001b[0m     amsgrad\u001b[39m=\u001b[39;49mamsgrad,\n\u001b[0;32m    343\u001b[0m     beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[0;32m    344\u001b[0m     beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[0;32m    345\u001b[0m     lr\u001b[39m=\u001b[39;49mlr,\n\u001b[0;32m    346\u001b[0m     weight_decay\u001b[39m=\u001b[39;49mweight_decay,\n\u001b[0;32m    347\u001b[0m     eps\u001b[39m=\u001b[39;49meps,\n\u001b[0;32m    348\u001b[0m     maximize\u001b[39m=\u001b[39;49mmaximize,\n\u001b[0;32m    349\u001b[0m     capturable\u001b[39m=\u001b[39;49mcapturable,\n\u001b[0;32m    350\u001b[0m     differentiable\u001b[39m=\u001b[39;49mdifferentiable,\n\u001b[0;32m    351\u001b[0m     grad_scale\u001b[39m=\u001b[39;49mgrad_scale,\n\u001b[0;32m    352\u001b[0m     found_inf\u001b[39m=\u001b[39;49mfound_inf,\n\u001b[0;32m    353\u001b[0m )\n","File \u001b[1;32mc:\\Users\\Steven\\anaconda3\\envs\\stock\\lib\\site-packages\\torch\\optim\\adamw.py:464\u001b[0m, in \u001b[0;36m_single_tensor_adamw\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[0;32m    462\u001b[0m         denom \u001b[39m=\u001b[39m (max_exp_avg_sqs[i]\u001b[39m.\u001b[39msqrt() \u001b[39m/\u001b[39m bias_correction2_sqrt)\u001b[39m.\u001b[39madd_(eps)\n\u001b[0;32m    463\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 464\u001b[0m         denom \u001b[39m=\u001b[39m (exp_avg_sq\u001b[39m.\u001b[39;49msqrt() \u001b[39m/\u001b[39m bias_correction2_sqrt)\u001b[39m.\u001b[39madd_(eps)\n\u001b[0;32m    466\u001b[0m     param\u001b[39m.\u001b[39maddcdiv_(exp_avg, denom, value\u001b[39m=\u001b[39m\u001b[39m-\u001b[39mstep_size)\n\u001b[0;32m    468\u001b[0m \u001b[39m# Lastly, switch back to complex view\u001b[39;00m\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}],"source":["trainer.train()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"elapsed":1883,"status":"ok","timestamp":1700963394349,"user":{"displayName":"Zixiao Wang","userId":"15997148754568851234"},"user_tz":300},"id":"AT_ucbzzYQJz","outputId":"114574c7-38a9-4e1b-ec06-632bd548d40c"},"outputs":[{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["(408, 2) (408,)\n"]}],"source":["predictions = trainer.predict(tokenized_datasets[\"validation\"])\n","print(predictions.predictions.shape, predictions.label_ids.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"elapsed":11389,"status":"ok","timestamp":1700963530184,"user":{"displayName":"Zixiao Wang","userId":"15997148754568851234"},"user_tz":300},"id":"yOWmQ73hU3x6","outputId":"0028021f-db65-45b6-eb85-56f9bb5d45f4"},"outputs":[{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["(1725, 2) (1725,)\n"]}],"source":["predictions = trainer.predict(tokenized_datasets[\"test\"])\n","print(predictions.predictions.shape, predictions.label_ids.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1058,"status":"ok","timestamp":1700963541269,"user":{"displayName":"Zixiao Wang","userId":"15997148754568851234"},"user_tz":300},"id":"UfdFyGXlU8Wv","outputId":"3159fe96-041c-48b1-ccd6-08d1c923e352"},"outputs":[{"data":{"text/plain":["PredictionOutput(predictions=array([[-4.521311 ,  3.7222323],\n","       [-3.4110165,  2.9014902],\n","       [-4.623328 ,  3.8644013],\n","       ...,\n","       [-4.612073 ,  3.8569236],\n","       [-4.514099 ,  3.6752856],\n","       [-4.265427 ,  3.4012394]], dtype=float32), label_ids=array([1, 1, 1, ..., 0, 1, 1]), metrics={'test_loss': 0.8783374428749084, 'test_accuracy': 0.8417391304347827, 'test_f1': 0.8847615027437737, 'test_runtime': 10.9624, 'test_samples_per_second': 157.356, 'test_steps_per_second': 1.277})"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["predictions"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1700963743112,"user":{"displayName":"Zixiao Wang","userId":"15997148754568851234"},"user_tz":300},"id":"syPX8lkoVuIa","outputId":"39fcba1e-d769-4c7c-ca88-ed7fe16f8a2f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Probabilities:\n"," [[2.6288169e-04 9.9973708e-01]\n"," [1.8101990e-03 9.9818975e-01]\n"," [2.0593787e-04 9.9979407e-01]\n"," ...\n"," [2.0983144e-04 9.9979013e-01]\n"," [2.7750764e-04 9.9972242e-01]\n"," [4.6795682e-04 9.9953210e-01]]\n","Predicted Labels:\n"," [1 1 1 ... 1 1 1]\n"]}],"source":["import numpy as np\n","from scipy.special import softmax\n","\n","# Apply softmax to convert logits to probabilities\n","probabilities = softmax(predictions.predictions, axis=1)\n","\n","# Get the predicted class labels\n","predicted_labels = np.argmax(probabilities, axis=1)\n","\n","print(\"Probabilities:\\n\", probabilities)\n","print(\"Predicted Labels:\\n\", predicted_labels)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.18"},"widgets":{"application/vnd.jupyter.widget-state+json":{"269dd0645ce744cc9bc3971a35cc2405":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"32d2a9a4a6c14e9493950097b9951fca":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3908d76eb97f42b38a052001ddc9e28c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3aa5adbbceda4811a17be59dd790467d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5de395af82c34a23aa3098467220f540":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_32d2a9a4a6c14e9493950097b9951fca","placeholder":"â€‹","style":"IPY_MODEL_8692ffe0f60a4568806780d0e34f11e3","value":"model.safetensors: 100%"}},"71c8537cfc2f40ec94f4e6a0923e35b9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3908d76eb97f42b38a052001ddc9e28c","placeholder":"â€‹","style":"IPY_MODEL_d1c6d682c07d43c7b47e27714603a014","value":" 440M/440M [00:01&lt;00:00, 224MB/s]"}},"8692ffe0f60a4568806780d0e34f11e3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8ad18caac29e40b79aed70184ee62142":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8f46e5c55db14d7ebd46250510b94fe8","max":440449768,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3aa5adbbceda4811a17be59dd790467d","value":440449768}},"8f46e5c55db14d7ebd46250510b94fe8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"95b5255c1f814063b80e70cb846bb697":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5de395af82c34a23aa3098467220f540","IPY_MODEL_8ad18caac29e40b79aed70184ee62142","IPY_MODEL_71c8537cfc2f40ec94f4e6a0923e35b9"],"layout":"IPY_MODEL_269dd0645ce744cc9bc3971a35cc2405"}},"d1c6d682c07d43c7b47e27714603a014":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}
