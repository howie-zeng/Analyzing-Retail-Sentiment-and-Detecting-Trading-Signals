{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"4TVkFuf0fVWk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1701148349779,"user_tz":300,"elapsed":1831,"user":{"displayName":"Zixiao Wang","userId":"15997148754568851234"}},"outputId":"0f8c55b2-8491-487b-c6c9-ace3c87511ef"},"outputs":[{"output_type":"stream","name":"stdout","text":["datasets is already installed.\n"]}],"source":["import importlib\n","\n","package_name = \"datasets\"\n","\n","try:\n","    importlib.import_module(package_name)\n","    print(f\"{package_name} is already installed.\")\n","except ImportError:\n","    print(f\"{package_name} is not installed. Installing it now...\")\n","    !pip install {package_name}\n","    print(f\"{package_name} has been successfully installed.\")"]},{"cell_type":"code","source":["import importlib\n","\n","package_name = \"accelerate\"\n","\n","try:\n","    importlib.import_module(package_name)\n","    print(f\"{package_name} is already installed.\")\n","except ImportError:\n","    print(f\"{package_name} is not installed. Installing it now...\")\n","    !pip install {package_name}\n","    print(f\"{package_name} has been successfully installed.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HNViMcmQNPXM","executionInfo":{"status":"ok","timestamp":1701148356513,"user_tz":300,"elapsed":6736,"user":{"displayName":"Zixiao Wang","userId":"15997148754568851234"}},"outputId":"5173c56d-ddcb-4f92-897b-c91cb9b9e74b"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["accelerate is already installed.\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from scipy.special import softmax\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","\n","from transformers import Trainer\n","from transformers import TrainingArguments\n","from transformers import AutoModelForSequenceClassification\n","from transformers import BertTokenizer, AutoTokenizer, DataCollatorWithPadding, BertForSequenceClassification\n","\n","from datasets import load_metric\n","from datasets import load_dataset\n","from datasets import load_from_disk\n","\n","import torch\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"],"metadata":{"id":"a3RHK3olFvWx","executionInfo":{"status":"ok","timestamp":1701148366023,"user_tz":300,"elapsed":9522,"user":{"displayName":"Zixiao Wang","userId":"15997148754568851234"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount(\"/content/drive\")\n","\n","%cd \"/content/drive/MyDrive/6386\"\n","\n","# from colab.file_utils import load_required\n","# load_required(force_reinstall_pytorch=True)"],"metadata":{"id":"YpDhZ8GTA-cx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1701148367816,"user_tz":300,"elapsed":1802,"user":{"displayName":"Zixiao Wang","userId":"15997148754568851234"}},"outputId":"7f438dc6-282b-4287-9656-e20e45490c13"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/MyDrive/6386\n"]}]},{"cell_type":"code","execution_count":5,"metadata":{"id":"WPtOlhLO96nG","executionInfo":{"status":"ok","timestamp":1701148367817,"user_tz":300,"elapsed":7,"user":{"displayName":"Zixiao Wang","userId":"15997148754568851234"}}},"outputs":[],"source":["import torch\n","torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"xP6V5YrDvRrk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1701148367817,"user_tz":300,"elapsed":6,"user":{"displayName":"Zixiao Wang","userId":"15997148754568851234"}},"outputId":"4197148e-baa8-4b84-8a3a-8b929a006572"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/6386\n"]}],"source":["import os\n","print(os.getcwd())"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"UHtD8mn9fWil","executionInfo":{"status":"ok","timestamp":1701148367817,"user_tz":300,"elapsed":4,"user":{"displayName":"Zixiao Wang","userId":"15997148754568851234"}}},"outputs":[],"source":["# !pip install datasets"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"f4tLexhaYQJt","executionInfo":{"status":"ok","timestamp":1701148369211,"user_tz":300,"elapsed":1398,"user":{"displayName":"Zixiao Wang","userId":"15997148754568851234"}},"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["a4e5aa76fa1b4db79a105322ad2980c4","64ab702751a843e9ae725d0b5d186c5e","2ea85c3b36d74ef7b2981e6684c1b150","22b03899e2bd4bb2b08bbdc5bc27e3dd","5a46c21cae334f6cafcaa81fa4a0b87c","5301b534574141f5b5eab3de3ca64dd5","18af35c263e64d79b4167d8102a769a5","051bac49bf204929ae7f41214697ca2b","71bf4375bbf1480e97292e659d4f03c7","ef2407bdf0cc47fdaf2e92b646d0fc59","7b20e23e9c8245159bd380562d579a20"]},"outputId":"7e77d324-68c3-4f26-801f-596a665c172a"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/2 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a4e5aa76fa1b4db79a105322ad2980c4"}},"metadata":{}}],"source":["raw_datasets = load_from_disk(\"finetune_data\")\n","# checkpoint = \"bert-base-uncased\"\n","# checkpoint = \"bert-base-cased\"\n","checkpoint = \"distilbert-base-uncased\"\n","tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n","\n","def tokenize_function(example):\n","    return tokenizer(example[\"text\"], padding=True, truncation=True)\n","\n","tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)\n","data_collator = DataCollatorWithPadding(tokenizer=tokenizer) # pad all the examples to the length of the longest element when we batch elements together â€” dynamic padding."]},{"cell_type":"code","execution_count":9,"metadata":{"id":"cf_GJiAZRsJ7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1701148369211,"user_tz":300,"elapsed":10,"user":{"displayName":"Zixiao Wang","userId":"15997148754568851234"}},"outputId":"ef5cb4d9-844e-4ddd-e71e-fcab00f6437f"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['text', 'label', 'input_ids', 'attention_mask'],\n","        num_rows: 8\n","    })\n","    validation: Dataset({\n","        features: ['text', 'label', 'input_ids', 'attention_mask'],\n","        num_rows: 2\n","    })\n","    test: Dataset({\n","        features: ['text', 'input_ids', 'attention_mask'],\n","        num_rows: 10\n","    })\n","})"]},"metadata":{},"execution_count":9}],"source":["tokenized_datasets"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"Z_E_Yiv1-S1d","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1701148369211,"user_tz":300,"elapsed":8,"user":{"displayName":"Zixiao Wang","userId":"15997148754568851234"}},"outputId":"9b507c70-4177-4562-d349-12719f92c830"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Wholesale inflation eases to 2.26% in February from 3.1% in previous month',\n"," 'DISH Break out watch over 38.10  ',\n"," \"$AMZN's stock faces pressure due to concerns about the company's third-party seller practices.\",\n"," 'ecent breakouts in DNKN GMC SBX appear to be the start of a group move. Still forming big cup bases. JVA also on watch.',\n"," \"Despite the hype, $AMC's stock faces challenges as theater attendance remains uncertain.\",\n"," 'The company said that sales in the three months to the end of March slid to EUR86 .4 m US$ 113.4 m from EUR91 .2 m last year .',\n"," '- I am pleased that Bjorn Wahlroos has accepted the nomination .',\n"," \"At the end of the review period , Nordic Aluminium 's order book stood at EUR 8.77 mn compared to EUR 7.04 in 2005 .\"]"]},"metadata":{},"execution_count":10}],"source":["tokenized_datasets['train']['text'][:10]"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"wxMvpJEuYQJx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1701148370520,"user_tz":300,"elapsed":1315,"user":{"displayName":"Zixiao Wang","userId":"15997148754568851234"}},"outputId":"420d1ea9-548a-471a-e95d-4ac71ede8e19"},"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-11-093e3287862a>:1: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n","  metric = load_metric(\"glue\", \"mrpc\")\n"]}],"source":["metric = load_metric(\"glue\", \"mrpc\")\n","\n","def compute_metrics(eval_preds):\n","    logits, labels = eval_preds\n","    predictions = np.argmax(logits, axis=-1)\n","    return metric.compute(predictions=predictions, references=labels)"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"Vp6LBZQmYxiG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1701148393704,"user_tz":300,"elapsed":23188,"user":{"displayName":"Zixiao Wang","userId":"15997148754568851234"}},"outputId":"4134ef5f-01f1-4a60-f589-b92d2fc36252"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (4.35.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.13.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.19.4)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.31.0)\n","Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.15.0)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.4.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.66.1)\n","Requirement already satisfied: torch!=1.12.0,>=1.10 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.1.0+cu118)\n","Requirement already satisfied: accelerate>=0.20.3 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.24.1)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.20.3->transformers[torch]) (5.9.5)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers[torch]) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers[torch]) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (3.1.2)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (2.1.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2023.7.22)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch!=1.12.0,>=1.10->transformers[torch]) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch!=1.12.0,>=1.10->transformers[torch]) (1.3.0)\n","Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.24.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.2)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n","Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.1.0+cu118)\n","Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.19.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.13.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.2)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.1.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2023.7.22)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"]}],"source":["!pip install transformers[torch]\n","!pip install accelerate -U"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"xzCuNDR6ZlB4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1701148393704,"user_tz":300,"elapsed":6,"user":{"displayName":"Zixiao Wang","userId":"15997148754568851234"}},"outputId":"aec8cff9-7892-4416-aed1-597027768c4d"},"outputs":[{"output_type":"stream","name":"stdout","text":["0.24.1\n"]}],"source":["import accelerate\n","print(accelerate.__version__)"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"9VOXyd2JYQJx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1701148406517,"user_tz":300,"elapsed":12817,"user":{"displayName":"Zixiao Wang","userId":"15997148754568851234"}},"outputId":"871f34c6-367f-4243-83ff-925b7f5aa5c6"},"outputs":[{"output_type":"stream","name":"stderr","text":["You are using a model of type distilbert to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['embeddings.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.8.attention.self.key.weight', 'embeddings.word_embeddings.weight', 'pooler.dense.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.self.query.weight', 'classifier.weight', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.7.attention.self.query.bias', 'pooler.dense.weight', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.5.output.dense.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.11.attention.output.dense.weight', 'embeddings.token_type_embeddings.weight', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.9.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.1.output.dense.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.10.output.dense.bias', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.weight', 'embeddings.position_embeddings.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.4.output.dense.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.4.attention.output.dense.bias', 'embeddings.LayerNorm.weight', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.6.output.dense.weight', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.attention.output.dense.bias', 'classifier.bias', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.10.attention.self.value.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["training_args = TrainingArguments(\n","    output_dir=\"test-trainer\",\n","    evaluation_strategy=\"epoch\",\n","    num_train_epochs=5,\n","    per_device_train_batch_size=16,\n","    per_device_eval_batch_size=256,\n","    # During the first 500 training steps, the learning rate gradually increases from 0 (or a small base rate) to the specified learning rate.\n","    # This gradual increase helps in stabilizing the training process and often leads to better performance, as it prevents the model from making too large updates too quickly.\n","    warmup_steps=500,\n","    weight_decay=0.01,\n","    logging_dir='logs',\n","    logging_steps=10,  # how frequently the training progress is logged\n","    save_strategy=\"epoch\",  # Set save strategy to \"epoch\" to save both best and last models\n","    load_best_model_at_end=True,\n","    metric_for_best_model=\"accuracy\",\n","    report_to=\"none\",  # disable wandb\n","    # fp16=True,  # Enable mixed precision training\n",")\n","# model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)\n","model = BertForSequenceClassification.from_pretrained(checkpoint, num_labels=2).to(device)\n","\n","trainer = Trainer(\n","    model,\n","    training_args,\n","    train_dataset=tokenized_datasets[\"train\"],\n","    eval_dataset=tokenized_datasets[\"validation\"],\n","    data_collator=data_collator,\n","    tokenizer=tokenizer,\n","    compute_metrics=compute_metrics,\n",")"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"_y3SU3UfYQJy","colab":{"base_uri":"https://localhost:8080/","height":304},"executionInfo":{"status":"ok","timestamp":1701148486547,"user_tz":300,"elapsed":80041,"user":{"displayName":"Zixiao Wang","userId":"15997148754568851234"}},"outputId":"4d0d97d8-7af8-4d3d-c6e5-8007feb7811d"},"outputs":[{"output_type":"stream","name":"stderr","text":["You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [5/5 01:18, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.922338</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>No log</td>\n","      <td>0.912998</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>No log</td>\n","      <td>0.894486</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>No log</td>\n","      <td>0.867271</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>No log</td>\n","      <td>0.831929</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=5, training_loss=0.7609110832214355, metrics={'train_runtime': 79.0206, 'train_samples_per_second': 0.506, 'train_steps_per_second': 0.063, 'total_flos': 842777599200.0, 'train_loss': 0.7609110832214355, 'epoch': 5.0})"]},"metadata":{},"execution_count":15}],"source":["trainer.train()"]},{"cell_type":"code","source":["output_dir = \"saved_model\"\n","os.makedirs(output_dir, exist_ok=True)\n","\n","# Save the best model and the last model\n","trainer.save_model(output_dir)\n","tokenizer.save_pretrained(output_dir)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"44lbB6o0Rv4j","executionInfo":{"status":"ok","timestamp":1701148489236,"user_tz":300,"elapsed":2697,"user":{"displayName":"Zixiao Wang","userId":"15997148754568851234"}},"outputId":"ac3e18be-1bf8-4b9c-a2c6-329ea8861a98"},"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["('saved_model/tokenizer_config.json',\n"," 'saved_model/special_tokens_map.json',\n"," 'saved_model/vocab.txt',\n"," 'saved_model/added_tokens.json',\n"," 'saved_model/tokenizer.json')"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","execution_count":17,"metadata":{"id":"yOWmQ73hU3x6","executionInfo":{"status":"ok","timestamp":1701148489236,"user_tz":300,"elapsed":15,"user":{"displayName":"Zixiao Wang","userId":"15997148754568851234"}},"colab":{"base_uri":"https://localhost:8080/","height":17},"outputId":"f2f73d44-6eb0-4301-b5f1-e9b05a422b44"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}}],"source":["predictions = trainer.predict(tokenized_datasets[\"test\"])\n","# print(predictions.predictions.shape, predictions.label_ids.shape)"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"UfdFyGXlU8Wv","executionInfo":{"status":"ok","timestamp":1701148489236,"user_tz":300,"elapsed":13,"user":{"displayName":"Zixiao Wang","userId":"15997148754568851234"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"b20b8b9e-a393-4b4a-8f18-8cade4ef88f7"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["PredictionOutput(predictions=array([[ 0.1966474 , -0.28340507],\n","       [ 0.20582949, -0.3134265 ],\n","       [ 0.17484556, -0.25611234],\n","       [ 0.23832574, -0.2616041 ],\n","       [ 0.24474546, -0.32449868],\n","       [ 0.19845586, -0.2908669 ],\n","       [ 0.2139138 , -0.22153285],\n","       [ 0.19264206, -0.24343744],\n","       [ 0.26210976, -0.29346582],\n","       [ 0.22881413, -0.28806487]], dtype=float32), label_ids=None, metrics={'test_runtime': 0.0924, 'test_samples_per_second': 108.262, 'test_steps_per_second': 10.826})"]},"metadata":{},"execution_count":18}],"source":["predictions"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"syPX8lkoVuIa","executionInfo":{"status":"ok","timestamp":1701148489237,"user_tz":300,"elapsed":13,"user":{"displayName":"Zixiao Wang","userId":"15997148754568851234"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"986509b2-c7d6-4ea2-f458-6b2d587811da"},"outputs":[{"output_type":"stream","name":"stdout","text":["Probabilities:\n"," [[0.61776024 0.38223973]\n"," [0.62697375 0.3730262 ]\n"," [0.6061024  0.39389762]\n"," [0.62244284 0.37755716]\n"," [0.6385888  0.36141124]\n"," [0.6199469  0.3800531 ]\n"," [0.60717356 0.39282647]\n"," [0.6073244  0.39267552]\n"," [0.6354282  0.36457178]\n"," [0.62641764 0.3735823 ]]\n","Predicted Labels:\n"," [0 0 0 0 0 0 0 0 0 0]\n"]}],"source":["probabilities = softmax(predictions.predictions, axis=1)\n","predicted_labels = np.argmax(probabilities, axis=1)\n","\n","print(\"Probabilities:\\n\", probabilities)\n","print(\"Predicted Labels:\\n\", predicted_labels)"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"fcpHYFOPwxnw","executionInfo":{"status":"ok","timestamp":1701148489237,"user_tz":300,"elapsed":12,"user":{"displayName":"Zixiao Wang","userId":"15997148754568851234"}}},"outputs":[],"source":["# true_labels = tokenized_datasets[\"test\"][\"label\"]\n","\n","# accuracy = accuracy_score(true_labels, predicted_labels)\n","# precision = precision_score(true_labels, predicted_labels)\n","# recall = recall_score(true_labels, predicted_labels, average='weighted')\n","# f1 = f1_score(true_labels, predicted_labels, average='weighted')\n","\n","# print(\"Accuracy:\", accuracy)\n","# print(\"Precision:\", precision)\n","# print(\"Recall:\", recall)\n","# print(\"F1 Score:\", f1)"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"wsWYpKLm-S1i","executionInfo":{"status":"ok","timestamp":1701148489237,"user_tz":300,"elapsed":11,"user":{"displayName":"Zixiao Wang","userId":"15997148754568851234"}}},"outputs":[],"source":["# helper_model.print_wrong_classifications(predicted_labels, true_labels, raw_datasets['test'])"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"XAqUIiTy-S1i","executionInfo":{"status":"ok","timestamp":1701148489237,"user_tz":300,"elapsed":11,"user":{"displayName":"Zixiao Wang","userId":"15997148754568851234"}}},"outputs":[],"source":["data = {'Predicted_Labels': predicted_labels}\n","df = pd.DataFrame(data)\n","df.to_csv('predicted_labels.csv', index=False)"]},{"cell_type":"markdown","source":["Use the saved model"],"metadata":{"id":"Z7A2dW2NUeAW"}},{"cell_type":"code","source":["# Define the path to the saved model directory\n","saved_model_dir = \"saved_model\"\n","\n","# Load the saved tokenizer\n","tokenizer = BertTokenizer.from_pretrained(saved_model_dir)\n","\n","# Load the saved model\n","model = BertForSequenceClassification.from_pretrained(saved_model_dir)\n","model"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-hDBmOXJTwSG","executionInfo":{"status":"ok","timestamp":1701148494477,"user_tz":300,"elapsed":5251,"user":{"displayName":"Zixiao Wang","userId":"15997148754568851234"}},"outputId":"276099b0-93fb-44ad-a928-d09ef9ac7a4e"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stderr","text":["The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n","The tokenizer class you load from this checkpoint is 'DistilBertTokenizer'. \n","The class this function is called from is 'BertTokenizer'.\n"]},{"output_type":"execute_result","data":{"text/plain":["BertForSequenceClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0-11): 12 x BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",")"]},"metadata":{},"execution_count":23}]},{"cell_type":"code","source":["trainer = Trainer(model=model)\n","predictions = trainer.predict(tokenized_datasets[\"test\"])\n","# Apply softmax to convert logits to probabilities\n","probabilities = softmax(predictions.predictions, axis=1)\n","\n","# Get the predicted class labels\n","predicted_labels = np.argmax(probabilities, axis=1)\n","\n","print(\"Probabilities:\\n\", probabilities)\n","print(\"Predicted Labels:\\n\", predicted_labels)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":243},"id":"Gm_UGCaeUcv4","executionInfo":{"status":"ok","timestamp":1701148495151,"user_tz":300,"elapsed":689,"user":{"displayName":"Zixiao Wang","userId":"15997148754568851234"}},"outputId":"d8ae9fa9-c497-436c-98e4-cfec322e89dd"},"execution_count":24,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Probabilities:\n"," [[0.6177605  0.38223955]\n"," [0.62697375 0.37302625]\n"," [0.6061025  0.3938975 ]\n"," [0.6224427  0.37755725]\n"," [0.63858867 0.36141133]\n"," [0.6199468  0.38005325]\n"," [0.6071735  0.39282653]\n"," [0.60732454 0.39267552]\n"," [0.6354282  0.36457175]\n"," [0.62641764 0.3735823 ]]\n","Predicted Labels:\n"," [0 0 0 0 0 0 0 0 0 0]\n"]}]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.18"},"widgets":{"application/vnd.jupyter.widget-state+json":{"a4e5aa76fa1b4db79a105322ad2980c4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_64ab702751a843e9ae725d0b5d186c5e","IPY_MODEL_2ea85c3b36d74ef7b2981e6684c1b150","IPY_MODEL_22b03899e2bd4bb2b08bbdc5bc27e3dd"],"layout":"IPY_MODEL_5a46c21cae334f6cafcaa81fa4a0b87c"}},"64ab702751a843e9ae725d0b5d186c5e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5301b534574141f5b5eab3de3ca64dd5","placeholder":"â€‹","style":"IPY_MODEL_18af35c263e64d79b4167d8102a769a5","value":"Map: 100%"}},"2ea85c3b36d74ef7b2981e6684c1b150":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_051bac49bf204929ae7f41214697ca2b","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_71bf4375bbf1480e97292e659d4f03c7","value":2}},"22b03899e2bd4bb2b08bbdc5bc27e3dd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ef2407bdf0cc47fdaf2e92b646d0fc59","placeholder":"â€‹","style":"IPY_MODEL_7b20e23e9c8245159bd380562d579a20","value":" 2/2 [00:00&lt;00:00, 11.01 examples/s]"}},"5a46c21cae334f6cafcaa81fa4a0b87c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5301b534574141f5b5eab3de3ca64dd5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"18af35c263e64d79b4167d8102a769a5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"051bac49bf204929ae7f41214697ca2b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"71bf4375bbf1480e97292e659d4f03c7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ef2407bdf0cc47fdaf2e92b646d0fc59":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7b20e23e9c8245159bd380562d579a20":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}