{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import helper as hp\n",
    "\n",
    "import os\n",
    "from abc import ABC, abstractmethod\n",
    "from collections import defaultdict\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import mplfinance as mpf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm import tqdm\n",
    "from statsmodels.tsa.stattools import adfuller, kpss\n",
    "from models import * \n",
    "\n",
    "\n",
    "current_path = os.getcwd()\n",
    "random_state = hp.RANDOM_STATE\n",
    "\n",
    "STOCKS = hp.STOCKS\n",
    "START_DATE = hp.START_DATE\n",
    "END_DATE = hp.END_DATE\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data fetched for RIVN\n",
      "Data fetched for BB\n",
      "Data fetched for SOFI\n",
      "Data fetched for GME\n",
      "Data fetched for AMC\n",
      "Data fetched for PLTR\n",
      "Data fetched for TSLA\n",
      "Data fetched for AAPL\n",
      "Data fetched for MSFT\n",
      "Data fetched for AMZN\n",
      "Data fetched for GOOG\n",
      "Data fetched for AMD\n",
      "Data fetched for NVDA\n",
      "Data fetched for QQQ\n",
      "Data fetched for SPY\n",
      "Data fetched for DIA\n",
      "Data fetched for ^IRX\n"
     ]
    }
   ],
   "source": [
    "# data fetching \n",
    "\n",
    "stock_data = {}\n",
    "for stock in STOCKS:\n",
    "    data_path = os.path.join(current_path, \"data\", f\"{stock}_{START_DATE}_{END_DATE}.csv\")\n",
    "    data = pd.read_csv(data_path)\n",
    "    stock_data[stock] = data\n",
    "stock_data = hp.preprocess_stock_data(stock_data, STOCKS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RIVN',\n",
       " 'BB',\n",
       " 'SOFI',\n",
       " 'GME',\n",
       " 'AMC',\n",
       " 'PLTR',\n",
       " 'TSLA',\n",
       " 'AAPL',\n",
       " 'MSFT',\n",
       " 'AMZN',\n",
       " 'GOOG',\n",
       " 'AMD',\n",
       " 'NVDA',\n",
       " 'QQQ',\n",
       " 'SPY',\n",
       " 'DIA',\n",
       " '^IRX']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "STOCKS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get the prediction of all stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RIVN\n",
      "BB\n",
      "SOFI\n",
      "GME\n",
      "AMC\n",
      "PLTR\n",
      "TSLA\n",
      "AAPL\n",
      "MSFT\n",
      "AMZN\n",
      "GOOG\n",
      "AMD\n",
      "NVDA\n"
     ]
    }
   ],
   "source": [
    "folder_name = 'data_with_signal'\n",
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)\n",
    "\n",
    "\n",
    "lag = 5\n",
    "window_size = 40\n",
    "starting_funds = 50000\n",
    "stationary = False\n",
    "columns_to_return = ['Date'] + hp.ORIGINAL_PRICE_FEATURES \n",
    "loss_fn = 'reg:squarederror' #'reg:squaredlogerror'\n",
    "params = {'n_estimators': 323, \n",
    "          'max_depth': 7, \n",
    "          'min_child_weight': 2, \n",
    "          'gamma': 0.10020565066030232, \n",
    "          'learning_rate': 0.08013623310286376, \n",
    "          'subsample': 0.9541002999199182, \n",
    "          'colsample_bytree': 0.659370350154071, \n",
    "          'reg_alpha': 0.029553047788818548, \n",
    "          'reg_lambda': 0.00021589152386430175\n",
    "          } \n",
    "\n",
    "for stock in STOCKS: #STOCKS\n",
    "    if stock in ['QQQ', 'SPY', 'DIA', '^IRX']:\n",
    "        continue\n",
    "    fromDate = START_DATE\n",
    "    toDate = END_DATE\n",
    "    print(stock)\n",
    "    make_new_predictions = False\n",
    "    file_path = os.path.join(folder_name, f'{stock}.csv')\n",
    "    image_folder_name = \"gallery\"\n",
    "\n",
    "    if os.path.exists(file_path):\n",
    "        df_old = pd.read_csv(file_path)\n",
    "        df_old['Date'] = pd.to_datetime(df_old['Date'])\n",
    "        latest_date = df_old['Date'].max()\n",
    "\n",
    "        if latest_date < pd.to_datetime(toDate):\n",
    "            make_new_predictions = True\n",
    "            latest_date_index = df_old[df_old['Date'] == latest_date].index[0]\n",
    "            new_start_index = max(latest_date_index - 250, 0)\n",
    "            fromDate = df_old.loc[new_start_index, 'Date']\n",
    "        continue\n",
    "    else:\n",
    "        make_new_predictions = True\n",
    "\n",
    "    if make_new_predictions:\n",
    "        X, y, df_stock = hp.prepare_data(stock_data, stock, fromDate, toDate, lag, stationary=stationary)\n",
    "        \n",
    "        xgboost_model = XGBoost(loss_fn, params)\n",
    "        xgboost_stock_predictor = StockPredictor(xgboost_model, window_size=window_size, stationary=stationary)\n",
    "        xgboost_stock_predictor.fit_predict(X, y, df_stock)\n",
    "\n",
    "        true_returns = xgboost_stock_predictor.true_returns\n",
    "        predicted_returns = xgboost_stock_predictor.predicted_returns\n",
    "\n",
    "        buys, sells, portfolio_value, portfolio_growth_percentage, dates, stock_prices = hp.trading_strategy(df_stock=df_stock, window_size=window_size, \n",
    "        true_returns=xgboost_stock_predictor.true_returns,\n",
    "        predicted_returns=xgboost_stock_predictor.predicted_returns,\n",
    "        starting_funds=50000)\n",
    "\n",
    "\n",
    "        df_res = stock_data[stock].copy()\n",
    "        df_res = df_res[columns_to_return] \n",
    "        df_res['buys'] = None\n",
    "        df_res['sells'] = None\n",
    "        df_res.loc[df_res.index[-len(buys):], 'buys'] = buys\n",
    "        df_res.loc[df_res.index[-len(sells):], 'sells'] = sells\n",
    "\n",
    "        df_res.to_csv(file_path, index=False)\n",
    "\n",
    "        # fig, fig2 = hp.plot_signal_returns(buys, sells, portfolio_value, portfolio_growth_percentage, dates, stock_prices, display=False)\n",
    "        # image_path = os.path.join(image_folder_name, f'{stock}.png')\n",
    "        # fig2.savefig(image_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
