{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import helper as hp\n",
    "\n",
    "import os\n",
    "from abc import ABC, abstractmethod\n",
    "from collections import defaultdict\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import mplfinance as mpf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm import tqdm\n",
    "from statsmodels.tsa.stattools import adfuller, kpss\n",
    "from models import * \n",
    "\n",
    "\n",
    "current_path = os.getcwd()\n",
    "random_state = hp.RANDOM_STATE\n",
    "\n",
    "STOCKS = hp.STOCKS\n",
    "START_DATE = hp.START_DATE\n",
    "END_DATE = hp.END_DATE\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data fetched for RIVN\n",
      "Data fetched for BB\n",
      "Data fetched for SOFI\n",
      "Data fetched for GME\n",
      "Data fetched for AMC\n",
      "Data fetched for PLTR\n",
      "Data fetched for TSLA\n",
      "Data fetched for AAPL\n",
      "Data fetched for MSFT\n",
      "Data fetched for AMZN\n",
      "Data fetched for GOOG\n",
      "Data fetched for AMD\n",
      "Data fetched for NVDA\n",
      "Data fetched for QQQ\n",
      "Data fetched for SPY\n",
      "Data fetched for DIA\n",
      "Data fetched for ^IRX\n"
     ]
    }
   ],
   "source": [
    "# data fetching \n",
    "\n",
    "stock_data = {}\n",
    "for stock in STOCKS:\n",
    "    data_path = os.path.join(current_path, \"data\", f\"{stock}_{START_DATE}_{END_DATE}.csv\")\n",
    "    data = pd.read_csv(data_path)\n",
    "    stock_data[stock] = data\n",
    "stock_data = hp.preprocess_stock_data(stock_data, STOCKS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get the prediction of all stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RIVN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 261/261 [01:09<00:00,  3.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  50%|█████     | 1756/3495 [04:44<04:41,  6.18it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\59836\\OneDrive\\桌面\\Analyzing-the-Correlation-Between-Retail-Traders--Sentiments-and-Equity-Market-Movements\\Stock_Analysis_Prediction\\Stock\\prediction_generator.ipynb Cell 6\u001b[0m line \u001b[0;36m5\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/59836/OneDrive/%E6%A1%8C%E9%9D%A2/Analyzing-the-Correlation-Between-Retail-Traders--Sentiments-and-Equity-Market-Movements/Stock_Analysis_Prediction/Stock/prediction_generator.ipynb#W5sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m xgboost_model \u001b[39m=\u001b[39m XGBoost(loss_fn, params)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/59836/OneDrive/%E6%A1%8C%E9%9D%A2/Analyzing-the-Correlation-Between-Retail-Traders--Sentiments-and-Equity-Market-Movements/Stock_Analysis_Prediction/Stock/prediction_generator.ipynb#W5sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m xgboost_stock_predictor \u001b[39m=\u001b[39m StockPredictor(xgboost_model, window_size\u001b[39m=\u001b[39mwindow_size, stationary\u001b[39m=\u001b[39mstationary)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/59836/OneDrive/%E6%A1%8C%E9%9D%A2/Analyzing-the-Correlation-Between-Retail-Traders--Sentiments-and-Equity-Market-Movements/Stock_Analysis_Prediction/Stock/prediction_generator.ipynb#W5sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m xgboost_stock_predictor\u001b[39m.\u001b[39;49mfit_predict(X, y, df_stock)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/59836/OneDrive/%E6%A1%8C%E9%9D%A2/Analyzing-the-Correlation-Between-Retail-Traders--Sentiments-and-Equity-Market-Movements/Stock_Analysis_Prediction/Stock/prediction_generator.ipynb#W5sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m true_returns \u001b[39m=\u001b[39m xgboost_stock_predictor\u001b[39m.\u001b[39mtrue_returns\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/59836/OneDrive/%E6%A1%8C%E9%9D%A2/Analyzing-the-Correlation-Between-Retail-Traders--Sentiments-and-Equity-Market-Movements/Stock_Analysis_Prediction/Stock/prediction_generator.ipynb#W5sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m predicted_returns \u001b[39m=\u001b[39m xgboost_stock_predictor\u001b[39m.\u001b[39mpredicted_returns\n",
      "File \u001b[1;32mc:\\Users\\59836\\OneDrive\\桌面\\Analyzing-the-Correlation-Between-Retail-Traders--Sentiments-and-Equity-Market-Movements\\Stock_Analysis_Prediction\\Stock\\models.py:102\u001b[0m, in \u001b[0;36mStockPredictor.fit_predict\u001b[1;34m(self, X, y, df_stock)\u001b[0m\n\u001b[0;32m     99\u001b[0m X_train, X_test \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39miloc[start:end], X\u001b[39m.\u001b[39miloc[end:end\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[0;32m    100\u001b[0m y_train, y_test \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39miloc[start:end], y\u001b[39m.\u001b[39miloc[end:end\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[1;32m--> 102\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mtrain(X_train, y_train)\n\u001b[0;32m    103\u001b[0m y_pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mpredict(X_test)\n\u001b[0;32m    104\u001b[0m predictions\u001b[39m.\u001b[39mappend(y_pred[\u001b[39m0\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\59836\\OneDrive\\桌面\\Analyzing-the-Correlation-Between-Retail-Traders--Sentiments-and-Equity-Market-Movements\\Stock_Analysis_Prediction\\Stock\\models.py:48\u001b[0m, in \u001b[0;36mXGBoost.train\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     38\u001b[0m params \u001b[39m=\u001b[39m {\n\u001b[0;32m     39\u001b[0m     \u001b[39m#'tree_method': 'hist',\u001b[39;00m\n\u001b[0;32m     40\u001b[0m     \u001b[39m#'device': device,  # Use GPU\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mrandom_state\u001b[39m\u001b[39m'\u001b[39m: helper\u001b[39m.\u001b[39mRANDOM_STATE\n\u001b[0;32m     45\u001b[0m }\n\u001b[0;32m     46\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m xgb\u001b[39m.\u001b[39mXGBRegressor(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams)\n\u001b[1;32m---> 48\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mfit(X, y)\n\u001b[0;32m     50\u001b[0m \u001b[39mfor\u001b[39;00m i, col \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(X\u001b[39m.\u001b[39mcolumns):\n\u001b[0;32m     51\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeature_importances[col] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mfeature_importances_[i]\n",
      "File \u001b[1;32mc:\\Users\\59836\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\xgboost\\core.py:729\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    727\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[0;32m    728\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[1;32m--> 729\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\59836\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\xgboost\\sklearn.py:1086\u001b[0m, in \u001b[0;36mXGBModel.fit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[0;32m   1075\u001b[0m     obj \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1077\u001b[0m (\n\u001b[0;32m   1078\u001b[0m     model,\n\u001b[0;32m   1079\u001b[0m     metric,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1084\u001b[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001b[0;32m   1085\u001b[0m )\n\u001b[1;32m-> 1086\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_Booster \u001b[39m=\u001b[39m train(\n\u001b[0;32m   1087\u001b[0m     params,\n\u001b[0;32m   1088\u001b[0m     train_dmatrix,\n\u001b[0;32m   1089\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_num_boosting_rounds(),\n\u001b[0;32m   1090\u001b[0m     evals\u001b[39m=\u001b[39;49mevals,\n\u001b[0;32m   1091\u001b[0m     early_stopping_rounds\u001b[39m=\u001b[39;49mearly_stopping_rounds,\n\u001b[0;32m   1092\u001b[0m     evals_result\u001b[39m=\u001b[39;49mevals_result,\n\u001b[0;32m   1093\u001b[0m     obj\u001b[39m=\u001b[39;49mobj,\n\u001b[0;32m   1094\u001b[0m     custom_metric\u001b[39m=\u001b[39;49mmetric,\n\u001b[0;32m   1095\u001b[0m     verbose_eval\u001b[39m=\u001b[39;49mverbose,\n\u001b[0;32m   1096\u001b[0m     xgb_model\u001b[39m=\u001b[39;49mmodel,\n\u001b[0;32m   1097\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[0;32m   1098\u001b[0m )\n\u001b[0;32m   1100\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_evaluation_result(evals_result)\n\u001b[0;32m   1101\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\59836\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\xgboost\\core.py:729\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    727\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[0;32m    728\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[1;32m--> 729\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\59836\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\xgboost\\training.py:192\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[0;32m    188\u001b[0m     evals_result\u001b[39m.\u001b[39mupdate(cb_container\u001b[39m.\u001b[39mhistory)\n\u001b[0;32m    190\u001b[0m \u001b[39m# Copy to serialise and unserialise booster to reset state and free\u001b[39;00m\n\u001b[0;32m    191\u001b[0m \u001b[39m# training memory\u001b[39;00m\n\u001b[1;32m--> 192\u001b[0m \u001b[39mreturn\u001b[39;00m bst\u001b[39m.\u001b[39;49mcopy()\n",
      "File \u001b[1;32mc:\\Users\\59836\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\xgboost\\core.py:1880\u001b[0m, in \u001b[0;36mBooster.copy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1872\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcopy\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mBooster\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m   1873\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Copy the booster object.\u001b[39;00m\n\u001b[0;32m   1874\u001b[0m \n\u001b[0;32m   1875\u001b[0m \u001b[39m    Returns\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1878\u001b[0m \u001b[39m        A copied booster model\u001b[39;00m\n\u001b[0;32m   1879\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1880\u001b[0m     \u001b[39mreturn\u001b[39;00m copy\u001b[39m.\u001b[39;49mcopy(\u001b[39mself\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\59836\\AppData\\Local\\Programs\\Python\\Python39\\lib\\copy.py:84\u001b[0m, in \u001b[0;36mcopy\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     82\u001b[0m copier \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mcls\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m__copy__\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m     83\u001b[0m \u001b[39mif\u001b[39;00m copier \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m---> 84\u001b[0m     \u001b[39mreturn\u001b[39;00m copier(x)\n\u001b[0;32m     86\u001b[0m reductor \u001b[39m=\u001b[39m dispatch_table\u001b[39m.\u001b[39mget(\u001b[39mcls\u001b[39m)\n\u001b[0;32m     87\u001b[0m \u001b[39mif\u001b[39;00m reductor \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\59836\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\xgboost\\core.py:1866\u001b[0m, in \u001b[0;36mBooster.__copy__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1865\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__copy__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mBooster\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m-> 1866\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__deepcopy__(\u001b[39mNone\u001b[39;49;00m)\n",
      "File \u001b[1;32mc:\\Users\\59836\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\xgboost\\core.py:1870\u001b[0m, in \u001b[0;36mBooster.__deepcopy__\u001b[1;34m(self, _)\u001b[0m\n\u001b[0;32m   1868\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__deepcopy__\u001b[39m(\u001b[39mself\u001b[39m, _: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mBooster\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m   1869\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Return a copy of booster.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1870\u001b[0m     \u001b[39mreturn\u001b[39;00m Booster(model_file\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\59836\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\xgboost\\core.py:1676\u001b[0m, in \u001b[0;36mBooster.__init__\u001b[1;34m(self, params, cache, model_file)\u001b[0m\n\u001b[0;32m   1674\u001b[0m     ptr \u001b[39m=\u001b[39m (ctypes\u001b[39m.\u001b[39mc_char \u001b[39m*\u001b[39m \u001b[39mlen\u001b[39m(handle))\u001b[39m.\u001b[39mfrom_buffer(handle)\n\u001b[0;32m   1675\u001b[0m     length \u001b[39m=\u001b[39m c_bst_ulong(\u001b[39mlen\u001b[39m(handle))\n\u001b[1;32m-> 1676\u001b[0m     _check_call(_LIB\u001b[39m.\u001b[39;49mXGBoosterUnserializeFromBuffer(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle, ptr, length))\n\u001b[0;32m   1677\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__dict__\u001b[39m\u001b[39m.\u001b[39mupdate(state)\n\u001b[0;32m   1678\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(model_file, (\u001b[39mstr\u001b[39m, os\u001b[39m.\u001b[39mPathLike, \u001b[39mbytearray\u001b[39m)):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "folder_name = 'data_with_signal'\n",
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)\n",
    "\n",
    "\n",
    "lag = 5\n",
    "window_size = 40\n",
    "starting_funds = 50000\n",
    "stationary = False\n",
    "columns_to_return = ['Date'] + hp.ORIGINAL_PRICE_FEATURES \n",
    "loss_fn = 'reg:squarederror' #'reg:squaredlogerror'\n",
    "params = {'n_estimators': 323, \n",
    "          'max_depth': 7, \n",
    "          'min_child_weight': 2, \n",
    "          'gamma': 0.10020565066030232, \n",
    "          'learning_rate': 0.08013623310286376, \n",
    "          'subsample': 0.9541002999199182, \n",
    "          'colsample_bytree': 0.659370350154071, \n",
    "          'reg_alpha': 0.029553047788818548, \n",
    "          'reg_lambda': 0.00021589152386430175\n",
    "          } \n",
    "\n",
    "for stock in STOCKS: #STOCKS\n",
    "    if stock in ['QQQ', 'SPY', 'DIA', '^IRX']:\n",
    "        continue\n",
    "    fromDate = START_DATE\n",
    "    toDate = END_DATE\n",
    "    print(stock)\n",
    "    make_new_predictions = False\n",
    "    file_path = os.path.join(folder_name, f'{stock}.csv')\n",
    "    image_folder_name = \"gallery\"\n",
    "    if os.path.exists(file_path):\n",
    "        df_old = pd.read_csv(file_path)\n",
    "        df_old['Date'] = pd.to_datetime(df_old['Date'])\n",
    "        latest_date = df_old['Date'].max()\n",
    "        if latest_date < pd.to_datetime(toDate):\n",
    "            make_new_predictions = True\n",
    "            latest_date_index = df_old[df_old['Date'] == latest_date].index[0]\n",
    "            new_start_index = max(latest_date_index - 250, 0)\n",
    "            fromDate = df_old.loc[new_start_index, 'Date']\n",
    "        continue\n",
    "    else:\n",
    "        make_new_predictions = True\n",
    "        \n",
    "    if make_new_predictions:\n",
    "        X, y, df_stock = hp.prepare_data(stock_data, stock, fromDate, toDate, lag, stationary=stationary)\n",
    "        \n",
    "        xgboost_model = XGBoost(loss_fn, params)\n",
    "        xgboost_stock_predictor = StockPredictor(xgboost_model, window_size=window_size, stationary=stationary)\n",
    "        xgboost_stock_predictor.fit_predict(X, y, df_stock)\n",
    "\n",
    "        true_returns = xgboost_stock_predictor.true_returns\n",
    "        predicted_returns = xgboost_stock_predictor.predicted_returns\n",
    "\n",
    "        buys, sells, portfolio_value, portfolio_growth_percentage, dates, stock_prices = hp.trading_strategy(df_stock=df_stock, window_size=window_size, \n",
    "        true_returns=xgboost_stock_predictor.true_returns,\n",
    "        predicted_returns=xgboost_stock_predictor.predicted_returns,\n",
    "        starting_funds=50000)\n",
    "\n",
    "        data_temp = {\"Date\": dates, \"Buys\": buys, \"Sells\": sells}\n",
    "        df_temp = pd.DataFrame(data_temp, columns=[\"Date\", \"Buys\", \"Sells\"])\n",
    "\n",
    "\n",
    "        df_res = stock_data[stock].copy()\n",
    "        df_res = df_res[columns_to_return] \n",
    "\n",
    "        df_res = df_res.merge(df_temp, on=\"Date\", how=\"inner\")\n",
    "\n",
    "        df_res.to_csv(file_path, index=False)\n",
    "\n",
    "        # fig, fig2 = hp.plot_signal_returns(buys, sells, portfolio_value, portfolio_growth_percentage, dates, stock_prices, display=False)\n",
    "        # image_path = os.path.join(image_folder_name, f'{stock}.png')\n",
    "        # fig2.savefig(image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "validation needed\n",
    "train 200, test one 5, validate on 5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
